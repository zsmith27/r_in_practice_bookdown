[
["index.html", "R in Practice 1 Preface", " R in Practice Zachary M. Smith 4/9/2019 1 Preface This document was originally developed for a workshop that I led at the 2019 Northeast Aquatic Biologists (NAB) conference. If you identify any issues or have any questions, please direct these questions to the GitHub issues page associated with the GitHub repository for this documnet (https://github.com/zsmith27/r_in_practice_bookdown/issues). "],
["introduction.html", "2 Introduction 2.1 Goals 2.2 What is R?", " 2 Introduction R statistical software and associated tools have the potential to increase your efficiency, simplify collaboration, and develop reproducible products. Often the biggest limitation to these tools is lack of awareness. This document is intended to provide you with an overview of some of the many R-related tools and is intended for individuals with at least a basic understanding of R. We will learn to create R functions, a robust project structure using R Studio, aesthetically pleasing documentation with R Markdown, and interactive tools with Shiny. In addition, we will delve into the ecosystem of packages developed by R Studio, known as the Tidyverse (e.g., dplyr, tidyr, purr, and ggplot2), which provide useful and intuitive functions for data manipulation, processing, and visualization. Overall, this document will provide you with the working knowledge of some of the most widely used R related tools available for your next project. 2.1 Goals To make you aware of the tools available to you. ggplot2 for creating figures dplyr and tidyr for data manipulation lubridate for handling and formatting dates rmarkdown for creating documents shiny for creating interactive apps To provide you with the vocabulary and understanding of R syntax to… Understand how to ask meaningful questions Understand how to use functions Interpret example code To provide you with an overview of project structure Understand where to start Understand tools that are available to you for project development RStudio R-Projects Git + GitHub rmarkdown R, like any other skill, is going to require you to invest a time to practice. I cannot help you with time management, but I can provide you with an 1) awareness of tools available and 2) the vocabulary and understanding of syntax to make practicing less frustrating. 2.1.1 Tip A good way to invest more time in R is to use R in situations where you would normally use MS Excel. 2.2 What is R? R is an open source programming language developed for statistical computing and graphic production. “R can be considered as a differenct implementation of S”, a language that was developed at Bell Laboratories (https://www.r-project.org/about.html). 2.2.1 Benefits of Using R Reproducibility: Standardized processes (e.g., functions, loops, documentation) When using MS Excel processes are often spread across multiple sheets or calculations are performed haphazardly within a single sheet. In general, this makes it very hard to interpret processes performmed and to reproduce the process. Power: Ability to perform simple and complex data manipulations, iterative processes, and calculations Access to more than 10,000 packages on CRAN New packages are constantly being developed New features are contsantly being added to existing packages 2.2.2 R Packages R packages are extensions of base R that provide additional features or provide alternative functionality. Availability CRAN (https://cran.r-project.org/) The Comprehensive R Archive Network (CRAN) FTP and web servers that store R Packages Packages are rwquired to meet certain standards GitHub (https://github.com) These packages are usually under development Contains development versions of many packages available on CRAN Custom (http://r-pkgs.had.co.nz/) You have the ability to create your own packages. "],
["quick-reference.html", "3 Quick Reference", " 3 Quick Reference Cheat Sheets: https://www.rstudio.com/resources/cheatsheets/ R Bloggers: https://www.r-bloggers.com/ Questions StackOverflow: https://stackoverflow.com R Community: https://community.rstudio.com/ Style Guides Hadely Wickham: http://style.tidyverse.org/index.html Google: https://google.github.io/styleguide/Rguide.xml Books and Papers R for Data Science: http://r4ds.had.co.nz/ The Art of R Programming: http://heather.cs.ucdavis.edu/~matloff/132/NSPpart.pdf Advanced R: http://adv-r.had.co.nz/ R Packages: http://r-pkgs.had.co.nz/ Tidy Data: https://www.jstatsoft.org/article/view/v059i10 Packages Shiny (Interactive Apps): https://shiny.rstudio.com/ Tutorials: https://shiny.rstudio.com/tutorial/ Leaflet (Interactive Maps): https://rstudio.github.io/leaflet/ DT (Interactive Tables): https://rstudio.github.io/DT/ Dygraphs (Interactive Time Series Plots): https://rstudio.github.io/dygraphs/ Plotly (Interactive Plots): https://plot.ly/r/ Tidyverse Packages (Ecosystem of Packages): https://www.tidyverse.org/ Rmarkdown (Documentation): https://rmarkdown.rstudio.com/lesson-1.html USGS GitHub: https://github.com/USGS-R dataRetrieval (Acquire data from the Water Quality Portal): https://cran.r-project.org/web/packages/dataRetrieval/vignettes/dataRetrieval.html EGRET (Analysis of long-term changes in water quality and streamflow): https://cran.r-project.org/web/packages/EGRET/vignettes/EGRET.pdf "],
["installation-links.html", "4 Installation Links 4.1 Updating Software and Packages", " 4 Installation Links Please install R and RStudio by following the links below. I highly recommend that you also install Git (link below) and create an account on GitHub (link below). The Git related tools are very useful but some workplaces will not allow the use of these tools for security reasons. Therefore, I will briefly cover Git but you are not required to use these tools during the workshop. Software Link R https://cran.r-project.org/bin/windows/base/ RStudio https://www.rstudio.com/products/rstudio/download/#download Git https://git-scm.com/downloads GitHub https://github.com 4.1 Updating Software and Packages 4.1.1 R Run the following code in the RGui, NOT in RStudio. The RGui should be installed when you install R. On my Windows machine, I access R by clicking on the R program file, “R x64 3.5.1”. You should get a window like this if you have opened the correct program. This code was copied from: https://www.r-statistics.com/2013/03/updating-r-from-r-on-windows-using-the-installr-package/). Make sure R Studio is closed before running this code within the RGui. # installing/loading the package: if(!require(installr)) { install.packages(&quot;installr&quot;); require(installr) } #load / install+load installr # using the package: updateR() 4.1.2 RStudio Open RStudio Click on “Help” on the toolbar Click on “Check for Updates” Follow instructions 4.1.3 R-Packages Open RStudio Click on “Tools” on the toolbar Click on “Check for Package Updates…” Follow instructions 4.1.3.1 Packages for Workshop Please run the following code within RStudio to make sure you have all of necessary packages for this workshop installed. Open RStudio Copy the following code package.vec &lt;- c(&quot;tidyverse&quot;, &quot;lubridate&quot;, &quot;knitr&quot;, &quot;rmarkdown&quot;, &quot;markdown&quot;, &quot;caTools&quot;, &quot;bitops&quot;, &quot;DT&quot;, &quot;leaflet&quot;, &quot;shiny&quot;, &quot;jsonlite&quot;, &quot;data.table&quot;, &quot;rprojroot&quot;, &quot;viridis&quot;) install.packages(package.vec) Paste the code into the Console within RStudio Hit Enter If prompted with “Do you want to restart R prior to installing?”, select “Yes” If prompted again then select “No” The packages should begin to install. This may take some time. "],
["rstudio-1.html", "5 RStudio 5.1 Create a New Script 5.2 RStudio Overview 5.3 Shortcuts", " 5 RStudio Open source integrated development environment (IDE) for R developed by R Studio. Edit scripts Run scripts Navigate files Organize projects Utilize version control (Git and Subversion) View static and interactive graphics And more… 5.1 Create a New Script Click on the new document buttion: Click on R Script: 5.2 RStudio Overview Once you have open an existing script or created a new script, following the instructions from the previous section, your RStudio should look similar to the following image. I have added labels to each of the windows. 5.2.1 Source Window This window appears when you open an exisiting R script or create a new R script Create a New Script. You will perform most of your write, edit, save, and execute your code. 5.2.2 Console Window Similar to the Source Window, code can also be executed in the console but it is not as easy to edit or save code written in the console window. Generally, I only write and execute code in the console window if I am just testing new code or want to quickly view data. 5.2.3 Environment, History, Connections, Build, and Git This window pane includes many features. Here we will only focus on the Environment Tab but I will briefly review the other tabs available. History Tab: view the order in which you have executed code. Connections: connect to databases and show your connections to those databases. Build: will only appear if you are building a custom package becuase it is used to compile the package and add it to your library. Git: will only appear if you connect your R Project to Git (see GitHub section). 5.2.3.1 Environment Tab Objects created in the Source Window or the Console Window are stored in the global environment. The Environment tab allows you to view the objects stored in the global environment. You can read more about environments in Hadely Wickham’s Advanced R book available for free online (http://adv-r.had.co.nz/Environments.html). In the Source Window example, I loaded the iris data frame into the global environment. This data frame will appear within Environment tab. We can see that this data frame has 150 obs. (rows) and 5 variables (columns). If we click on the blue circle next to iris, we will be provided with a glimpse into the data frame. Below we can see the columns that make up the data frame, the type of data they represent, and the first view values in a given column. The first four columns, Sepal.Length, Sepal.Width, Petal.Length, and Petal.Width, are numeric (num) data type. The last column, Species, is a factor data type. If we click on the view table button. The data frame will open in a tab within the Source Window. Here we can scroll through and view all of the data within the iris data frame. If we want to view a subset of data we can apply a global filter by filtering with… or we can apply column specific fileters if we click the filter button. The global environment can be cleared by using the clear button. When your global environment has been cleared the Environment Tab will look like this… 5.2.4 Files, Plots, Packages, Help, and Viewer 5.2.5 Files Tab Open R Scripts by clicking. View file structure without leaving RStudio. Helpful for finding files to import or to verify a file exported. More beneficial if working in an R Project. 5.2.6 Plots Tab View plots created in script. You can manually export from this tab. Generally recommended that you write script to do this (reproducible). 5.2.7 Packages Tab View packages installed on your computer. Button to update installed packages. Button to install new packages. 5.2.8 Help Tab General Structure: Description, Usage, Arguments, See Also, and Examples. Important to review to understand how the function works. 5.2.9 Viewer Tab Similar to the Plots Tab but allows you to view interactive plots. 5.3 Shortcuts A list of all RStudio shortcuts can be found here: https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts You can also press Alt+Shift+K within RStudio to pull up a list of shortcuts. Below are my favorite shortcuts: Description Windows…Linux Mac Run Current Line/Selection Ctrl+Enter Command+Enter Insert Code Section Ctrl+Shift+R Command+Shift+R Re-indent Lines Ctrl+I Command+I Reformat Selection Ctrl+Shift+A Command+Shift+A Find and Replace Ctrl+F Command+F Undo Ctrl+Z Command+Z Redo Ctrl+Shift+Z Command+Shift+Z Cut Ctrl+X Command+X Copy Ctrl+C Command+C Paste Ctrl+V Command+V Select All Ctrl+A Command+A Insert Pipe Operator Ctrl+Shift+M Command+Shift+M Insert Code Chunk Ctrl+Alt+I Command+Option+I Restart R Session Ctrl+Shift+F10 Command+Shift+F10 "],
["r-project.html", "6 R Project 6.1 Create a New R Project 6.2 Navigate Between Packages 6.3 Recommended Workflow", " 6 R Project Overview Easier to access files (relative path) Relative paths help prevent broken paths In general, DO NOT use setwd() Will work if the project folder is moved to a new location on you local machine or moved to a new machine. Designed to easily integrate with version control (GIT) In general, all data, scripts, and output should be stored within the project directory. 6.1 Create a New R Project Create a new R project by clicking on the dropdown menu at the top right of RStudio and selecting “New Project” Select “New Directory” within the “Create Project” window Select “New Project” within the “Project Type” window Enter a project name(below I have given the name “new_project”), the project directory (where the project should live), and select “Create Project” Tip: Create a “project” folder that will act as your parent directory for all R projects. This will make it much easier to navigate to and between projects. A new session specific to your R project will start within RStudio There are a number of ways to tell which project is open… 6.2 Navigate Between Packages Quickly navigate between recently opened R projects by clicking on the dropdown menu at the top right of RStudio and selecting the project of interest. 6.3 Recommended Workflow Set up a GitHub repository. Create an R-project connected to the GitHub repository. Develop R-scripts. Push and pull project changes to and from GitHub. "],
["version-control.html", "7 Version Control 7.1 Git Resources 7.2 Link R Studio to GitHub Repository 7.3 Push and Pull Repository Changes in R Studio 7.4 Repository Branch 7.5 Merge Branches", " 7 Version Control Version control software keeps track of changes made to files. This provides the user with the ability to revert changes back to an earlier version, a backup of the files, and simplifies collaboration efforts. Git is a free open source version control system (https://git-scm.com/) and GitHub is a platform that allows the user to store their changes made via Git in the form of repositories (https://github.com/). R Studio has integrated Git into their R Studio IDE, making it easy to work with repositories from GitHub (https://support.rstudio.com/hc/en-us/articles/200532077-Version-Control-with-Git-and-SVN). Git will need to be installed locally (https://git-scm.com/downloads) and a GitHub account will need to be to be created (https://github.com/join?source=header-home) before these tools can be accessible from R Studio. 7.1 Git Resources Link: https://git-scm.com/doc 7.2 Link R Studio to GitHub Repository Below are the steps for initializing an R project file connected to a GitHub repository. It is much easier to create the GitHub repository prior to creating project. Create a new repository online on your GitHub account Navigate to your GitHub account (https://github.com/) Click on the “Repositories” tab Click on the “New” button to create a new repository Add a repository name, initialize the creation of a README file, and click “creat repository” Find the “clone or download” button on your repository page and copy the SSH key Create a new project in R Studio (File -&gt; New Project). Select Version Control and Git (Version Control -&gt; Git). I believe R Studio should automatically recognize Git on your computer but I had to specify where the git.exe was located by going to Tools -&gt; Global Options -&gt; Git/SVN -&gt; locate git.exe (my file path: “C:/Users/zsmith/AppData/Local/Programs/Git/bin/git.exe”). Paste the repository URL (https://github.com/username/repository.git) into the “Repository URL” box in the R Studio window. Copy the repository URL from GitHub. Within the repositories “Code” tab select the green button labeled “Clone or Download.” Copy the HTTPS URL provided. Use the “Create project as sub-directory of:” box to manage where you want to store the project on your computer. Click “Create Project.” The project will now be linked to the GitHub repository. A “Git” tab will appear within the “Environment” pane in R Studio. If you have an existing R project without a repository on GitHub and you would like to start using version control, I recommend starting from scratch. Create a GitHub repository, connect to a new R Studio project file, and copy the old R project files into the new R project folder. 7.3 Push and Pull Repository Changes in R Studio Whenever updates are made to the files within the R project folder, they will be queued in the “Git” tab that appears in “Environment” pane in R Studio. 7.3.1 Pull Pull every time you open the project to make sure you have the most up-to-date version of the repository. Changes may have been made by you from a different computer or by one of your collaborators. 7.3.2 Commit A commit is an informative message to yourself or collaborators indicating why you made a change. When the “Commit” button is selected, an “RStudio: Review Changes” window will appear. In this window all of the altered files will appear in the upper left pane. By selecting an individual file in the upper left pane, the user can see the changes that were implemented in bottom pane of the “RStudio: Review Changes” window. Deletions will appear in red, while insertions will appear green. One or more files can be staged and then the user has three options: 1) Revert, 2) Ignore, or 3) Commit. The “Revert” button will revert the staged file(s) to the previous state that is available in the GitHub repository. The “Ignore” button will add the staged file(s) to the .gitignore file. The .gitignore file informs Git that a file should not be added to the GitHub repository and subsequent changes to the file should not be added to the GitHub repository. GitHub will prevent users from pushing large data sets, and thus large data sets should be added to the .gitignore file. Also, files containing sensitive information (e.g., usernames or passwords) should be added to the .gitingore file. Staged file(s) require a commit message, an informative message indicating why a change was made, prior to being committed. All commits remain local until the “Push” button is used to send the changes to the GitHub repository. 7.3.3 Push Push commits from R Studio to the GitHub repository. 7.4 Repository Branch When a repository is created it consist of a single branch labeled “master.” The master branch will suffice as you first develop the app. However, you may reach a point where the master branch is functioning well (without any known issues) but you want to make some dramatic development changes. Rather than committing the changes to the master branch (potentially breaking your working product), you can create a new isolated branch to work on your development changes. In this case, the branch would clone the current state of the master, and then any edits made to the new branch would not impact the master branch. When working in R Studio with GitHub, use the drop-down menu (located in the top right corner of the Git tab in the Environment pane) to select the branch you want to work on. In the image below I clicked on “master” and now I can see three branches are available for this project: 1) master, 2) Development, and 3) Zsmith. Simply select a name to change the branch you are working on. 7.4.1 Create a New Branch Creating a new branch is relatively simple. There are three ways that I know how to create a repository branch: 1) via R Studio, 2) via GitHub, and 3) via Git Shell. 7.4.1.1 R Studio In the “Git” tab of the Environment pane in R Studio, there is button for creating a new branch. Click on this button: 7.4.1.2 GitHub Log on to your GitHub online GitHub account (https://github.com/) and navigate to the repository you are working on. Under the “Code” tab, click on the “Branch:” button. This will produce a drop down menu (as seen in the image below), where you can select an existing branch or create a new branch by typing the name you want to assign your new branch into the input box labeled “Find or create a branch.” Once you type in the new name, a new box will appear in the dropdown menu that says “Create Branch”. Click on this box to create the new branch. 7.4.1.3 Git Shell The Git Shell can be accessed via R Studio in the Git tab of the Environment pane. Click on the “More” dropdown menu and then click “Shell…” (see image below). A new window will appear. Use this link to understand how to create and work with branches in the Git Shell: https://git-scm.com/book/en/v2/Git-Branching-Basic-Branching-and-Merging. 7.5 Merge Branches After you have vetted a new branch, you can merge the new branch with the master branch (or some other branch). The merge will join all the changes made in the new branch and all of the changes made in the master branch. You may run into conflict issues if both branches updated the same section of code (https://help.github.com/articles/resolving-a-merge-conflict-using-the-command-line/). Merging branches is not as simple as creating branches. As far as I know, branches can only be merged using the Git Shell (see Git Shell to learn how to access the Git Shell). Use the following link to understand how to merge branches: https://help.github.com/articles/merging-an-upstream-repository-into-your-fork/ "],
["r-markdown.html", "8 R Markdown 8.1 Benefits 8.2 Basic Overview 8.3 Create a New Document 8.4 Editing 8.5 Compile the Document 8.6 File Management 8.7 Child Documents 8.8 Parameterized Reports", " 8 R Markdown R Markdown: The Definitive Guide: https://bookdown.org/yihui/rmarkdown/ RStudio Lessons: https://rmarkdown.rstudio.com/lesson-1.html Markdown is a markup language for developing and formating documents. R Markdown is an R-package that allows the user to integrate text, R-code, and R-code output into a well formatted document (e.g., HTML, MS Word, PDF). My recommendation is to create an R Markdown file for every R-project. The intention is to document as much of the project as possible. R Markdown provides a more readable document, with better descriptions of how and why an activity was performed, than a standard R script with a few commented lines. 8.1 Benefits Reproducible: Document steps of an investigation or scientific study reproducibility crisis. Collaborative: Easy to work with others on investigations and scientific studies. Efficient: Generate and update reports automatically (e.g., HTML, MS Word, and PDF). Engaging: Embed interactive figures, maps, and tables in reports (HTML only). Source: https://plotly-book.cpsievert.me/images/gapminder-highlight-animation.gif 8.2 Basic Overview Use markdown syntax, some of which is shown in the table below, to format the document. Source: https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf Once the document is complete (formated with markdown syntax with integrated R code) the document can be knit (rendered) using the package knitr. Here is a simple example showing the raw R Markdown (Rmd) file before knitting (rendering) and after knitting. The colors on the far left are ther to help identify elements pre- and post-knitting. R is not the only language supported by R Markdown. The following languages and more can be integrated into an R Markdown file. 8.3 Create a New Document Click on the new document buttion: Click on R Markdown: Provide a “Title:”, select the “Defualt Output Format:”, and click “OK” A new R Markdown document will appear with some instructions and example text/code. Delete everything after the YAML header: --- title: &quot;Untitled&quot; author: &quot;Zachary M. Smith&quot; date: &quot;September 23, 2018&quot; output: html_document --- 8.4 Editing Again, your best resource for learning how to use R Markdown will be the R Markdown website (https://rmarkdown.rstudio.com/lesson-1.html), but I will describe some of the general features here. 8.4.1 YAML Header YAML: YAML Ain’t Markup Language 8.4.1.1 Standard 8.4.1.2 Table of Contents (TOC) 8.4.1.3 Floating Table of Contents (TOC) 8.4.2 Heading Text Heading text follows one or more hash-sign(s) (#). The number of hash-signs determines the hierarchy of headings. For example, “# Heading 1” would represent the primary heading, “## Heading 2” would represent the secondary heading, “###Heading 3” would represent the tertiary heading, and so forth. 8.4.3 Plain Text Simply add text below the YAML header. 8.4.4 Insert Code Chunks To insert a code chunk, press Ctrl + Alt + i in the source pane (top left pane in the default settings of Studio). A code chunk will appear: Inside the code chunk you can write and run R-code. If you print the output of your R-code it will appear below the code chunk in the source pane and the printed output will appear in the final compiled document. This is useful for producing figures and tables. 8.5 Compile the Document To view the html document, you must compile the document using Knit. Follow these steps to Knit the document: Find and click the Knit button (it looks like a ball of yarn) in the toolbar above the editor window. If a window appears saying “Install Required Packages” for R Markdown, install the necessary packages for knitting the document. The compiled file will be saved in the same directory as your Rmd file (your R Markdown file). 8.6 File Management I store the R Markdown file(s) in a sub-directory labeled “markdown” within the R-project folder (rproject/markdown). 8.7 Child Documents In general, I find that a single R Markdown file quickly becomes unwieldy. I recommend breaking the document up into multiple “child” documents and sourcing these child documents in a parent document. My child documents generally represent major subsections of the document. I store the parent R Markdown file in the “markdown” folder (rproject/markdown) and the child R Markdown files in a sub-directory of my “markdown” folder called “sections” (rproject/markdown/sections). In the parent file, the child files are sourced within the code chunk header using “child = ‘sections/example.Rmd’. After sourcing all the child chunks, the parent file can be knit (compiled) like a normal R markdown document. The child documents cannot be run in the parent file. 8.7.1 Extract and Run R-Code from R Markdown Files The parent file is great for organizing sections of your document, but the child documents cannot be executed within R Studio like a normal code chunk. Without the ability to easily execute the R code within the child documents it can become very difficult to develop new child documents because new child documents often depend on upstream code execution. Imagine you have a parent document that sources child sections which import your data and clean your data. You now want to visualize your data; accordingly, you begin to develop a visualization child document, which depends on information from the upstream child sections. It would be inefficient and inappropriate to perform all the steps in the upstream child sections within the visualization section. Therefore, you need an effective way to execute the upstream child sections while you continue to develop the visualization section. The inefficient way of doing this is to open each child Rmd file in R Studio and execute them manually in the correct sequence. This becomes tedious after you have three or more documents (imagine doing this for 10+ child sections). The most efficient way that I have found to run upstream child sections is to extract the R-code chunks from each Rmd file, save them in a “raw_scripts” folder, and then source/execute the scripts within a regular R script file (.R). 8.7.1.1 R Code In this section we establish the file path to the folder that contains all the child documents. The names of the child documents are extracted and stored as a vector. The grepl() function is used to retain only the Rmd files stored in the vector. sections.path &lt;- file.path(rprojroot::find_root(&quot;r_in_practice.Rproj&quot;), &quot;markdown&quot;, &quot;sections&quot;) r.files.vec &lt;- list.files(sections.path) r.files.vec &lt;- r.files.vec[grepl(&quot;.Rmd&quot;, r.files.vec)] Next, a file path is specified for the R-scripts that will be extracted from the R Markdown documents; I place these files within a “raw_script/extracted” folder. The map() function from the purrr package is used to loop through each file in the vector (r.files.vec). Within the map() loop, the purl() function from knitr is used to extract the R-code from the R Markdown documents and save the code to the specified folder. extracted.path &lt;- file.path(rprojroot::find_root(&quot;r_in_practice.Rproj&quot;), &quot;markdown&quot;, &quot;raw_scripts&quot;, &quot;extracted&quot;) purrr::map(r.files.vec, function(file.i) { # print(file.i) file.name &lt;- gsub(&quot;.Rmd&quot;, &quot;&quot;, file.i) extracted.file &lt;- paste0(file.name, &quot;.R&quot;) knitr::purl( file.path(sections.path, file.i), file.path(extracted.path, extracted.file) ) }) Finally, create a vector of file names (source.vec) stored in the “raw_script/extracted” folder. You will want to type these out manually (do not use list.files() functions) because in this format you can easily comment out certain scripts and only run the scripts of interest. The map() is then used to loop through each specified file in source.vec. Keep in mind that the order of the file names specified in source.vec will determine the order that these files are executed in the map() function; therefore, order the files in source.vec from furthest upstream to furthest downstream. Each iteration of the loop, executes (sources) the specified R-script. source.vec &lt;- c( &quot;introduction.R&quot;, &quot;quick_reference.R&quot;, &quot;installation_updates.R&quot;, &quot;r_project.R&quot;, &quot;version_control.R&quot; ) purrr::map(source.vec, function(source.i) { source(file.path(extracted.path, source.i)) }) Once all the R-scripts extracted from the upstream child R Markdown files have been executed, you can begin or continue work on a new child R Markdown document. I keep all the above code in a single R-script and execute the entire script each time I use this file to make sure all of the files are up-to-date. 8.8 Parameterized Reports https://www.coursera.org/lecture/reproducible-templates-analysis/adding-parameters-in-a-document-template-6fQwc "],
["base-r.html", "9 Base R 9.1 Data Types", " 9 Base R 9.1 Data Types 9.1.1 Numeric (Double) Can include integers and decimal numbers (continuous variables) EXAMPLE: is.numeric(c(1, 2, 3.5, 6.7)) ## [1] TRUE is.numeric(c(1, 2, 3, 6)) ## [1] TRUE is.numeric(1:5) ## [1] TRUE is.numeric(c(TRUE, FALSE, TRUE)) ## [1] FALSE is.numeric(c(&quot;a&quot;, 2, 3, 6)) ## [1] FALSE is.numeric(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;)) ## [1] FALSE 9.1.2 Integer Only whole numbers (discrete variables) From is.integer()help file: “is.integer(x) does not test if x contains integer numbers!” EXAMPLE: is.integer(c(1, 2, 3.5, 6.7)) ## [1] FALSE is.integer(c(1, 2, 3, 6)) ## [1] FALSE is.integer(1:5) ## [1] TRUE is.integer(c(TRUE, FALSE, TRUE)) ## [1] FALSE is.integer(c(&quot;a&quot;, 2, 3, 6)) ## [1] FALSE is.integer(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;)) ## [1] FALSE 9.1.3 Logical TRUE or FALSE values EXAMPLE: is.logical(c(1, 2, 3.5, 6.7)) ## [1] FALSE is.logical(c(1, 2, 3, 6)) ## [1] FALSE is.logical(1:5) ## [1] FALSE is.logical(c(TRUE, FALSE, TRUE)) ## [1] TRUE is.logical(c(&quot;a&quot;, 2, 3, 6)) ## [1] FALSE is.logical(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;)) ## [1] FALSE 9.1.4 Character Alphanumeric EXAMPLE: is.character(c(1, 2, 3.5, 6.7)) ## [1] FALSE is.character(c(1, 2, 3, 6)) ## [1] FALSE is.character(1:5) ## [1] FALSE is.character(c(TRUE, FALSE, TRUE)) ## [1] FALSE is.character(c(&quot;a&quot;, 2, 3, 6)) ## [1] TRUE is.character(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;)) ## [1] TRUE 9.1.5 Factor A special integer vector to assign order Use: assign custom order to categorical variables If you were to sort a character vector, R would sort the vector alphabetically. EXAMPLE: is.factor(c(1, 2, 3.5, 6.7)) ## [1] FALSE is.factor(c(1, 2, 3, 6)) ## [1] FALSE is.factor(1:5) ## [1] FALSE is.factor(c(TRUE, FALSE, TRUE)) ## [1] FALSE is.factor(c(&quot;a&quot;, 2, 3, 6)) ## [1] FALSE is.factor(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;)) ## [1] FALSE Example of sorting a character vector. sort(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;)) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; Example of sorting a factor vector. sort(factor(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), levels = c(&quot;d&quot;, &quot;a&quot;, &quot;c&quot;, &quot;b&quot;))) ## [1] d a c b ## Levels: d a c b as.numeric(sort(factor( c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), levels = c(&quot;d&quot;, &quot;a&quot;, &quot;c&quot;, &quot;b&quot;) ))) ## [1] 1 2 3 4 9.1.5.1 Example In this example there are three stations on the Hudson River (i.e., Port of Albany, West Point, and Pier 84). Although this is a tidal river, we would generally want to sort and plot this data from upstream to downstream (i.e., Port of Albany, West Point, and Pier 84). The table below shows how sort() would arrange the data if it is stored as a character vs. factor type. "],
["data-structures.html", "10 Data Structures 10.1 Vectors 10.2 Matrices 10.3 Arrays 10.4 Data Frames 10.5 Lists", " 10 Data Structures Common Data Structures: Vectors 1 Dimensional Homogenous data type Matrices 2 Dimensional Homogenous data type Arrays Greater than 2 Dimensions Homogenous data type Data Frames 2 Dimensional Heterogenous data types Lists Can contain various data types (vectors, matrices, arrays, and data frames) Heterogenous data types 10.1 Vectors 1 Dimensional Homogenous data type Numeric vector c(1, 2, 3, 4, 5) ## [1] 1 2 3 4 5 Character Vector c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; Logical vector c(TRUE, FALSE, TRUE, FALSE, TRUE) ## [1] TRUE FALSE TRUE FALSE TRUE 10.2 Matrices 2 Dimensional Homogenous data type matrix(c(1:5, 2, 7, 4, 9, 20, 40, 23, 64, 67, 80, 3, 76, 29, 59, 91), ncol = 4) ## [,1] [,2] [,3] [,4] ## [1,] 1 2 40 3 ## [2,] 2 7 23 76 ## [3,] 3 4 64 29 ## [4,] 4 9 67 59 ## [5,] 5 20 80 91 10.3 Arrays Greater than 2 Dimensions Homogenous data type array(c(c(1:5, 2, 7, 4, 9, 20, 40, 23, 64, 67, 80, 3, 76, 29, 59, 91, 1, 3, 5, 7, 9), c(2, 3, 34, 45, 57, 26, 74, 42, 91, 20, 1, 0, 82, 31, 45, 1, 0, 1, 0, 1, 9:5), c(1, 0, rep(1, 3), rep(0, 5), 1, 0, 1, 1, 0, rep(1, 5), 0, 0, 1, 1, 0)), c(5, 5, 3)) ## , , 1 ## ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 2 40 3 1 ## [2,] 2 7 23 76 3 ## [3,] 3 4 64 29 5 ## [4,] 4 9 67 59 7 ## [5,] 5 20 80 91 9 ## ## , , 2 ## ## [,1] [,2] [,3] [,4] [,5] ## [1,] 2 26 1 1 9 ## [2,] 3 74 0 0 8 ## [3,] 34 42 82 1 7 ## [4,] 45 91 31 0 6 ## [5,] 57 20 45 1 5 ## ## , , 3 ## ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 0 1 1 0 ## [2,] 0 0 0 1 0 ## [3,] 1 0 1 1 1 ## [4,] 1 0 1 1 1 ## [5,] 1 0 0 1 0 10.4 Data Frames 2 Dimensional Heterogenous data types data.frame( Numeric = c(1, 2, 3, 4, 5), Charcter = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;), Logical = c(TRUE, FALSE, TRUE, FALSE, TRUE), stringsAsFactors = FALSE ) ## Numeric Charcter Logical ## 1 1 A TRUE ## 2 2 B FALSE ## 3 3 C TRUE ## 4 4 D FALSE ## 5 5 E TRUE 10.5 Lists Can contain various data types (Vectors, Matrices, Arrays, and Data Frames) Heterogenous data types list( c(TRUE, FALSE, TRUE, FALSE, TRUE), matrix(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;AB&quot;, &quot;BC&quot;, &quot;CD&quot;, &quot;DE&quot;, &quot;EF&quot;, rep(&quot;BLAH&quot;, 5), &quot;TEXT&quot;, &quot;text&quot;, &quot;TEXT&quot;, &quot;text&quot;, &quot;TEXT&quot;), ncol = 4), array(c(c(1:5, 2, 7, 4, 9, 20, 40, 23, 64, 67, 80, 3, 76, 29, 59, 91, 1, 3, 5, 7, 9), c(2, 3, 34, 45, 57, 26, 74, 42, 91, 20, 1, 0, 82, 31, 45, 1, 0, 1, 0, 1, 9:5), c(1, 0, rep(1, 3), rep(0, 5), 1, 0, 1, 1, 0, rep(1, 5), 0, 0, 1, 1, 0)), c(5, 5, 3)), data.frame( Numeric = c(1, 2, 3, 4, 5), Charcter = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;), Logical = c(TRUE, FALSE, TRUE, FALSE, TRUE), stringsAsFactors = FALSE ) ) ## [[1]] ## [1] TRUE FALSE TRUE FALSE TRUE ## ## [[2]] ## [,1] [,2] [,3] [,4] ## [1,] &quot;A&quot; &quot;AB&quot; &quot;BLAH&quot; &quot;TEXT&quot; ## [2,] &quot;B&quot; &quot;BC&quot; &quot;BLAH&quot; &quot;text&quot; ## [3,] &quot;C&quot; &quot;CD&quot; &quot;BLAH&quot; &quot;TEXT&quot; ## [4,] &quot;D&quot; &quot;DE&quot; &quot;BLAH&quot; &quot;text&quot; ## [5,] &quot;E&quot; &quot;EF&quot; &quot;BLAH&quot; &quot;TEXT&quot; ## ## [[3]] ## , , 1 ## ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 2 40 3 1 ## [2,] 2 7 23 76 3 ## [3,] 3 4 64 29 5 ## [4,] 4 9 67 59 7 ## [5,] 5 20 80 91 9 ## ## , , 2 ## ## [,1] [,2] [,3] [,4] [,5] ## [1,] 2 26 1 1 9 ## [2,] 3 74 0 0 8 ## [3,] 34 42 82 1 7 ## [4,] 45 91 31 0 6 ## [5,] 57 20 45 1 5 ## ## , , 3 ## ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 0 1 1 0 ## [2,] 0 0 0 1 0 ## [3,] 1 0 1 1 1 ## [4,] 1 0 1 1 1 ## [5,] 1 0 0 1 0 ## ## ## [[4]] ## Numeric Charcter Logical ## 1 1 A TRUE ## 2 2 B FALSE ## 3 3 C TRUE ## 4 4 D FALSE ## 5 5 E TRUE "],
["data-structure-manipulation.html", "11 Data Structure Manipulation 11.1 Assignment Opperator (&lt;-) 11.2 Manipulting Vectors 11.3 Manipulating Data Frames 11.4 Importing Data", " 11 Data Structure Manipulation 11.1 Assignment Opperator (&lt;-) The assignment opperator (&lt;-) is used to assign data structures to a named object that will be stored in the Environment. The object on the left side of the assignment opperator is going to refer to a new or existing data object. The object to the right of the assignment opperator is going to represent the data that we want to store in the object to the left of the opperator. When the code is executed, the object will be stored in the Environment, which is visible within the RStudio Environment window. For example, the integer vector from 1-5, created using c(1:5), is stored with the object name, int.vec. The image below this code chunk, shows the Environment before and after the code has been executed. We can see that int.vec has been added to the Environment. int.vec &lt;- c(1:5) Here is an example of a data frame being stored as an object, example.df. See Environment Tab section to review the helpful tools available in RStudio for viewing elements of a data frame. example.df &lt;- data.frame( Numeric = c(1, 2, 3, 4, 5), Character = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;), Logical = c(TRUE, FALSE, TRUE, FALSE, TRUE), stringsAsFactors = FALSE ) 11.2 Manipulting Vectors char.vec &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;) char.vec ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; char.vec[3] ## [1] &quot;c&quot; char.vec[c(1, 3)] ## [1] &quot;a&quot; &quot;c&quot; The colon opperator can be helpful for grabbing a sequential range. Here I am specifiying elements 1, 2, and 3 of char.vec. char.vec[1:3] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; 11.3 Manipulating Data Frames This data frame will be used as an example in this section. example.df &lt;- data.frame( Numeric = c(1, 2, 3, 4, 5), Character = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;), Logical = c(TRUE, FALSE, TRUE, FALSE, TRUE), stringsAsFactors = FALSE ) knitr::kable(example.df) Numeric Character Logical 1 A TRUE 2 B FALSE 3 C TRUE 4 D FALSE 5 E TRUE When dealing with data frames think of the square brackets ([, ]) as a coordinate system. Values specified to the left of the comma in [, ] represents rows, while everything to the right of the comma represents columns. example.df[, 1] ## [1] 1 2 3 4 5 example.df[1, ] ## Numeric Character Logical ## 1 1 A TRUE example.df[1, 1] ## [1] 1 example.df[1:2, 1:2] ## Numeric Character ## 1 1 A ## 2 2 B example.df$Numeric ## [1] 1 2 3 4 5 example.df[, &quot;Numeric&quot;] ## [1] 1 2 3 4 5 example.df[example.df$Numeric == 1, ] ## Numeric Character Logical ## 1 1 A TRUE example.df[example.df$Character %in% c(&quot;A&quot;, &quot;C&quot;), ] ## Numeric Character Logical ## 1 1 A TRUE ## 3 3 C TRUE example.df[example.df$Character %in% c(&quot;A&quot;, &quot;C&quot;), &quot;Numeric&quot;] ## [1] 1 3 11.4 Importing Data 11.4.1 file_path file_path() is a clean way of specifying a file path. You do not have to remember if you need to seperate folders by “/” or “\", file.path will do it for you (It’s”/\", by the way). file.path(&quot;data&quot;, &quot;zms_thesis-macro_2017-06-18.csv&quot;) ## [1] &quot;data/zms_thesis-macro_2017-06-18.csv&quot; 11.4.2 read.csv One way to import data is to use read.csv(). This is specific to importing comma seperated value (CSV) files. In general, you just need to supply the path to the CSV file (tell read.csv() where the cSV file lives) and specify stringsAsFactors = FALSE. The default for read.csv() is stringsAsFactors = TRUE, which will make all columns filled with character strings factor columns upon import. This typically not the behaviour we want, so I recommend setting stringsAsFactors = FALSE. My opinion is that factors should be specifically defined after the data has been imported. I have provided my thesis data as an example data set for this document. The data represents benthic macroinvertebrate data collected in the littoral zone of Onondaga, Otisco, and Cazenovia lakes taxa.df &lt;- read.csv(file.path(&quot;data&quot;, &quot;zms_thesis-macro_2017-06-18.csv&quot;), stringsAsFactors = FALSE) DT::datatable(taxa.df, options = list(scrollX = TRUE)) "],
["style-guide.html", "12 Style Guide 12.1 Names 12.2 Spacing and Indenting", " 12 Style Guide Code style is more important than you may first imagine. Adopting a consistent style will make it easier for you and your collaborators to read and comprehend your code. Please review and in future R-code use Hadley Wickham’s (http://style.tidyverse.org/index.html) style guide. As mentioned in Hadely Wickham’s guide, his guide is adapted from Google’s style guide (https://google.github.io/styleguide/Rguide.xml); therefore, there are many similarities. I do not want to recreate these style guides here, instead I want to highlight what I believe are some of the more important features. 12.1 Names File names, function names, and column names should not contain spaces. It is very easy to create a name with two subsequent spaces by mistake and very frustrating to later trouble shoot why your call to this name in your R code is returning an error. I use snake case, “snake_case”, instead of “snake case” or “snakeCase;” the later, “snakeCase”, is known as camel case. Many programmers use camel case but I find I make more typos when I use this naming scheme and in find snake case easier to read. Please use snake case. 12.1.1 Object Names: Discriptive Suffix For object names, I prefer a style similar to the one found in Google’s style guide but with a descriptive suffix. I cannot provide a reference to this style but at one point I adopted a descriptive suffix that describes the objects class (e.g., data frame = “.df”, vector = “.vec”, scalar = “.scal”, list = “.lst”, matrix = “.mat”, and time series = “.ts”). I have found this simple naming scheme to be very helpful because I immediately know what the intended class of the object at any point that it is referenced in the script. This makes it easier to identify a bug if an object named “object.df” is represented in my RStudio Environment pane as a vector or list. Examples: # Data Frame------------------------------------------------------------------- my.df &lt;- data.frame() # Vector----------------------------------------------------------------------- my.vec &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) my.scal &lt;- &quot;a&quot; my.vec &lt;- c(1:3) my.scal &lt;- 1 # Matrix----------------------------------------------------------------------- my.mat &lt;- matrix() # List------------------------------------------------------------------------- my.lst &lt;- list() # Time Series------------------------------------------------------------------ my.ts &lt;- ts() 12.2 Spacing and Indenting Please follow the spacing (http://style.tidyverse.org/syntax.html#spacing) and indenting (http://style.tidyverse.org/syntax.html#indenting) guide lines provided in Hadely Wickham’s style guide. I find it very difficult to follow code that does not adhere to these guidelines. The following “good” and “bad” examples will create the exact same data frame. However, the “good” example is much easier to read and interpret. Good Example: good.df &lt;- data.frame( alphabet = letters, square_root = sqrt(81), add = 1 + 1, subtract = 1 - 1, multiply = 2 * 2, divide = 2 / 2, power = 2^2 ) Bad Example: bad.df&lt;-data.frame(alphabet=letters,square_root=sqrt(81),add=1+1,subtract=1-1,multiply=2*2,divide=2/2,power=2^2) "],
["writing-functions.html", "13 Writing Functions", " 13 Writing Functions It is highly recommended that you learn to write your own functions. In general, anytime you have the urge to copy and paste code to perform a similar process on a different aspect of your data you should instead write a function. A function is a single standardized process that you apply to similar data sets. Therefore, it is easier to update the function rather than multiple chunks of code that have been copied and pasted throughout your script. For example, imagine you have copied and pasted code ten times. Later you want to update the code. Now you have to update all ten instances of the code. This is time consuming and it would be easy to miss or add a typo to one of the ten instances. If the process is stored as a function, you make one update to the function and that update is applied in a standardized manner to all ten instances of your data. The image below provides an overview of the pieces necessary to create a function. Use function() to initialize the creation of a new function. Within function you will, generally, add arguements (in example below: x, y) that you will want to be able to modify. Curly brackets ({}) following the function() call define the extent of the body of the function being created. Within the curly brackets is wher most of the work is performed; this is the area where we insert our code that we want to become a standarized process. This example is very simple, just x -y, but you could insert 100+ lines of code into a function. However, really lenghty functions are poor practice. Finally, the function needs to be stored as an object. Use the assignment opperator (&lt;-) to assign this function an object name (e.g., subtract &lt;-). Let us actually create this function. subtract &lt;- function(x, y) { x - y } Once this function has been executed, it is stored as a object named “subtract”. This object can be seen in the Environment window. Now we can test our function. subtract(x = 10, y = 5) ## [1] 5 We can get the same results without specifically calling out x and y. R will assume that you understand the order of the arguements is x, y, and therefore 10 will represent x and 5 will represent y. subtract(10, 5) ## [1] 5 If we reverse the order, then 5 represents x and 10 represents y. subtract(5, 10) ## [1] -5 Our intention with the created subtract function is to subtract one value from another. However, the code in the chunk below will run. In this code x represents the numeric vector c(1, 2, 3) and y represents the numeric vector c(3, 2, 1). subtract(c(1, 2, 3), c(3, 2, 1)) ## [1] -2 0 2 We only want this function to execute if x and y are each of length one. A conditional if() statement combined with a stop() function can be used to prevent the function from working on data that does not meet our requirements (x of length 1 and y of length 1). Note that this update would normarlly be made to the orginal function call up above. subtract() is only updated here to show the progression of our development of this function. subtract &lt;- function(x, y) { if (length(x) != 1 | length(y) != 1) stop(&quot;x and y must length 1&quot;) x - y } Now if a vector of length 3 is provided for the x or y arguments, the function will return an error with the message “x and y must length 1.” This is the message that was defined in the stop() call within the creation of the subtract() function above. subtract(c(1, 2, 3), c(3, 2, 1)) ## Error in subtract(c(1, 2, 3), c(3, 2, 1)): x and y must length 1 Double check that the original values still work. subtract(10, 5) ## [1] 5 "],
["loops.html", "14 Loops 14.1 for loop 14.2 apply family", " 14 Loops 14.1 for loop for (i in c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)){ print(paste(&quot;This iteration represents&quot;, i)) } ## [1] &quot;This iteration represents a&quot; ## [1] &quot;This iteration represents b&quot; ## [1] &quot;This iteration represents c&quot; 14.2 apply family Link: https://www.datacamp.com/community/tutorials/r-tutorial-apply-family These functions also perform loops but are a little bit more specific in how the loop is performed or how the output is returned relative to the for loop. 14.2.1 apply The iris data set will be used as an example. The Species column will be dropped from iris for this exercies and this object will be stored as iris.df. iris.df &lt;- head(iris[, names(iris) != &quot;Species&quot;]) Apply a function by row. In this case, sum() by row. apply(iris.df, 1, sum) ## 1 2 3 4 5 6 ## 10.2 9.5 9.4 9.4 10.2 11.4 Apply a function by column. In this case, sum() by column. apply(iris.df, 2, sum) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 29.7 20.3 8.7 1.4 14.2.2 lapply lapply() loops through a vector or list and returns a list, hence the “L” in lapply(). Compare the output below to the for loop example. lapply() returns a list of strings that were printed in the for loop example. lapply(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), function(i) { paste(&quot;This iteration represents&quot;, i) }) ## [[1]] ## [1] &quot;This iteration represents a&quot; ## ## [[2]] ## [1] &quot;This iteration represents b&quot; ## ## [[3]] ## [1] &quot;This iteration represents c&quot; Now compare the apply() example summing rows above to this lapply() call lapply(1:nrow(iris.df), function(i) { sum(iris.df[i, ]) }) ## [[1]] ## [1] 10.2 ## ## [[2]] ## [1] 9.5 ## ## [[3]] ## [1] 9.4 ## ## [[4]] ## [1] 9.4 ## ## [[5]] ## [1] 10.2 ## ## [[6]] ## [1] 11.4 Now compare the apply() example summing columns above to this lapply() call. lapply(1:ncol(iris.df), function(i) { sum(iris.df[, i]) }) ## [[1]] ## [1] 29.7 ## ## [[2]] ## [1] 20.3 ## ## [[3]] ## [1] 8.7 ## ## [[4]] ## [1] 1.4 14.2.3 sapply sapply() loops through a vector or list and returns a vector. Compare the output below to the similar for() loop and lapply() examples. sapply() returns a vector of strings that were printed in the for() loop example and the strings returned as a list in the lapply() example. sapply(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), function(i) { paste(&quot;This iteration represents&quot;, i) }) ## a b ## &quot;This iteration represents a&quot; &quot;This iteration represents b&quot; ## c ## &quot;This iteration represents c&quot; Now compare the apply() and lapply() examples summing rows above to this sapply() call. sapply(1:nrow(iris.df), function(i) { sum(iris.df[i, ]) }) ## [1] 10.2 9.5 9.4 9.4 10.2 11.4 Now compare the apply() and lapply() examples summing columns above to this sapply() call. sapply(1:ncol(iris.df), function(i) { sum(iris.df[, i]) }) ## [1] 29.7 20.3 8.7 1.4 "],
["tidyverse.html", "15 Tidyverse 15.1 Tidyverse Directory 15.2 magrittr", " 15 Tidyverse Link: https://www.tidyverse.org/ Great Place to Start: https://r4ds.had.co.nz/ The tidyverse is an ecosystem of packages that work well together and often make it easier to deal with data in R. These packages are mostly developed and maintained by RStudio staff but contributions are frequently made by members of the R community. WARNING: These packages are very helpful but many are not yet stable. There is potential that a function could undergo a large change or be depreciated in the future. This can have a significant negative impact on the reproducibility of your work. The functions in tidyverse packages will generally provide helpful messages indicating if a function has been depreciated and indicate the function that has taken its place. Instead of loading each tidyverse package individually, library(tidyverse) will load the most frequently used packages: ggplot2, purrr, tibble, dplyr, tidyr, stringr, readr, and forcats. library(tidyverse) ## -- Attaching packages -------------------- tidyverse 1.2.1 -- ## v ggplot2 3.1.1 v purrr 0.3.2 ## v tibble 2.1.1 v dplyr 0.8.0.1 ## v tidyr 0.8.3 v stringr 1.4.0 ## v readr 1.3.1 v forcats 0.4.0 ## Warning: package &#39;ggplot2&#39; was built under R version 3.5.3 ## Warning: package &#39;tibble&#39; was built under R version 3.5.3 ## Warning: package &#39;tidyr&#39; was built under R version 3.5.3 ## Warning: package &#39;purrr&#39; was built under R version 3.5.3 ## -- Conflicts ----------------------- tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() 15.1 Tidyverse Directory Pipe Operator magrittr Data Structure tibble Data Manipulation dplyr tidyr Loops purrr Visualization ggplot2 Dates and Datetimes lubridate hms Strings stringr glue Factors forcats Import Data readr readXl haven Store Binary Data blob 15.2 magrittr Link: https://magrittr.tidyverse.org/ Index of Functions: https://magrittr.tidyverse.org/reference/index.html library(magrittr) ## ## Attaching package: &#39;magrittr&#39; ## The following object is masked _by_ &#39;.GlobalEnv&#39;: ## ## subtract ## The following object is masked from &#39;package:purrr&#39;: ## ## set_names ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract 15.2.1 Example Data This vector will be used as an example for this section. Notice that all of the strings are slightly different. I frequently find issues like this in data sets I have been given. We will assume that all of the strings are intended to represent the same information, and therefore require some processing to standardize the strings. x &lt;- c(&quot;example 1&quot;, &quot; example 1&quot;, &quot;example 1 &quot;, &quot;example_1&quot;) 15.2.2 Pipe Operator (%&gt;%) I often find that the pipe operator, %&gt;%, from the magrittr package is confusing to those unfamiliar with the tidyverse. It takes a little while to wrap your head around the pipe operator but once you do I think you will find its use makes R code more legible. In essence, base R works from the inside-out, while the pipe operator presents the code in a linear fashion. For example, imagine you have a character vector x and you want to trim leading/trailing white space, then keep only unique strings, and then convert all characters to lowercase. In base R, the code would look like the code in the chunk below. Again, base R works from the inside-out, so first trimws() is used to remove leading/trailing white space, then tolower() is used to convert all characters to lowercase, and finally str_replace() is used to replace any spaces with an underscore. str_replace(tolower(trimws(x)), &quot; &quot;, &quot;_&quot;) ## [1] &quot;example_1&quot; &quot;example_1&quot; &quot;example_1&quot; &quot;example_1&quot; Using the pipe operator, the code functions just the same but it is formatted in a more legible manner: x is piped to trims() the output of trims() is piped to tolower() the output of tolower() is piped to str_replace() the output of str_replace() is returned The pipe operator presents the functions in the order you intend them to be performed; therefore, the code should be easier to read and more intuitive, which should in turn reduce errors. x %&gt;% trimws() %&gt;% tolower() %&gt;% str_replace(&quot; &quot;, &quot;_&quot;) ## [1] &quot;example_1&quot; &quot;example_1&quot; &quot;example_1&quot; &quot;example_1&quot; Most tidyverse packages (e.g., NOT ggplot2) are designed to work well with the pipe operator. The pipe operator pushes the call on the left side of the operator to the first position of the function on the right of the operator. Therefore, functions developed outside of the tidyverse may not automatically work will with the pipe operator. A . can be used as an a placeholder. In the examples above, str_replace(), from the stringr package, was used. This function is designed to work well with the pipe operator but what if we wanted to use gsub(), the base R equivalent to str_replace()? str_replace() structure: str_replace(string, pattern, replacement) gsub() structure: gsub(pattern, replacement, x) In gsub(), the x arguement is equivalent to the string arguement in str_replace(). Notice the difference in the order of the arguements. In str_replace(), string is the first arguement, but in gsub(), x is the last arguement. Therefore, when using the pipe operator with gsub(), the placeholder (.) must be used becuase the output from x %&gt;% trimws() %&gt;% tolower() by default will be piped into the pattern arguement, the first arguement. Here is the error recieved if the placeholder (.) is NOT used: x %&gt;% trimws() %&gt;% tolower() %&gt;% gsub() ## Error in gsub(.): argument &quot;x&quot; is missing, with no default Here is how the placeholder(.) would be used in a gsub() call. pattern and replacement are speciefied as normal, while x = . indicates where the output from x %&gt;% trimws() %&gt;% tolower() should be used. x %&gt;% trimws() %&gt;% tolower() %&gt;% gsub(pattern = &quot; &quot;, replacement = &quot;_&quot;, x = .) ## [1] &quot;example_1&quot; &quot;example_1&quot; &quot;example_1&quot; &quot;example_1&quot; "],
["dplyr.html", "16 dplyr", " 16 dplyr Link: https://dplyr.tidyverse.org/ Index of Functions: https://dplyr.tidyverse.org/reference/index.html Cheat Sheet: https://github.com/rstudio/cheatsheets/blob/master/data-transformation.pdf Chapter of R for Data Science: https://r4ds.had.co.nz/transform.html Unofficial Example: https://rpubs.com/williamsurles/293454 suppressPackageStartupMessages( library(dplyr) ) 16.0.1 Example Data Import the example data. This data represents benthic macroinvertebrate data collected in the littoral zone of Onondaga, Otisco, and Cazenovia lakes taxa.df &lt;- file.path(&quot;data&quot;, &quot;zms_thesis-macro_2017-06-18.csv&quot;) %&gt;% read.csv(stringsAsFactors = FALSE) DT::datatable(taxa.df, options = list(scrollX = TRUE)) env.df &lt;- file.path(&quot;data&quot;, &quot;zms_thesis-env_2017-06-18.csv&quot;) %&gt;% read.csv(stringsAsFactors = FALSE) DT::datatable(env.df, options = list(scrollX = TRUE)) 16.0.2 Rename Definition: give a new name to a specified column(s). Link: https://dplyr.tidyverse.org/reference/select.html In the example below, the columns lat and long are renamed to latitude and longitude, respectively. If names(taxa.df) is called, elements 5 and 6 are now represented by “latitude” and “longitude”, respectively. taxa.df &lt;- taxa.df %&gt;% rename(latitude = lat, longitude = long) names(taxa.df) ## [1] &quot;unique_id&quot; &quot;lake&quot; &quot;station_id&quot; &quot;sample_number&quot; ## [5] &quot;latitude&quot; &quot;longitude&quot; &quot;agency_code&quot; &quot;method&quot; ## [9] &quot;date&quot; &quot;count&quot; &quot;life_stage&quot; &quot;final_id&quot; ## [13] &quot;taxon_level&quot; &quot;phylum&quot; &quot;subphylum&quot; &quot;class&quot; ## [17] &quot;subclass&quot; &quot;order&quot; &quot;suborder&quot; &quot;family&quot; ## [21] &quot;subfamily&quot; &quot;tribe&quot; &quot;genus&quot; &quot;species&quot; ## [25] &quot;picked&quot; &quot;squares&quot; 16.0.3 Filter Definition: subset rows using logical statements. Link: https://dplyr.tidyverse.org/reference/filter.html In the example below, taxa.df is subset to only include rows where the unique_id column matches the string “caz_1_1”. filter.df &lt;- taxa.df %&gt;% filter(unique_id == &quot;caz_1_1&quot;) DT::datatable(filter.df, options = list(scrollX = TRUE)) You can apply multiple filters separate by commas. The filters are applied from the top down. In the example below, two filters are applied within the filter() call: unique_id == \"caz_1_1\" order %in% c(\"ephemeroptera\", \"trichoptera\") The first logical statement is the same as the filter from the code chunk above, which keeps only rows associated with the sample “caz_1_1”. Then, the order column is subset the data to only include rows represented by ephemeroptera (mayfly) or trichoptera (caddisfly) taxa. filter.df &lt;- taxa.df %&gt;% filter(unique_id == &quot;caz_1_1&quot;, order %in% c(&quot;ephemeroptera&quot;, &quot;trichoptera&quot;)) DT::datatable(filter.df, options = list(scrollX = TRUE)) 16.0.4 Select Definition: subset of columns. Link: https://dplyr.tidyverse.org/reference/select.html Often we are not interested in all columns in a data frame. select() can be used to subset the columns to only include columns of interest. In the example below, the filter.df data frame, created in the Filter section, is subset to only include three columns: 1) final_id, count, and unique_id. select.df &lt;- filter.df %&gt;% select(unique_id, final_id, count) knitr::kable(select.df) unique_id final_id count caz_1_1 baetidae 1 caz_1_1 caenis 14 caz_1_1 agraylea 1 caz_1_1 oxyethira 2 caz_1_1 hydroptilidae 1 The same operation can be performed by chaining the functions together with the pipe operator. taxa.df is first filtered to only include rows that meet our specified logical statements and then only the columns unique_id, final_id, and count are retained. select.df &lt;- taxa.df %&gt;% filter(unique_id == &quot;caz_1_1&quot;, order %in% c(&quot;ephemeroptera&quot;, &quot;trichoptera&quot;)) %&gt;% select(unique_id, final_id, count) knitr::kable(select.df) unique_id final_id count caz_1_1 baetidae 1 caz_1_1 caenis 14 caz_1_1 agraylea 1 caz_1_1 oxyethira 2 caz_1_1 hydroptilidae 1 Reorder columns. Maybe you would prefer to see the columns in the following order: final_id unique_id count reorder.df &lt;- taxa.df %&gt;% filter(unique_id == &quot;caz_1_1&quot;, order %in% c(&quot;ephemeroptera&quot;, &quot;trichoptera&quot;)) %&gt;% select(final_id, unique_id, count) knitr::kable(reorder.df) final_id unique_id count baetidae caz_1_1 1 caenis caz_1_1 14 agraylea caz_1_1 1 oxyethira caz_1_1 2 hydroptilidae caz_1_1 1 16.0.4.1 everything Definition: helper function for select. Specifies all columns not already specified in the select() call. Link: https://dplyr.tidyverse.org/reference/select.html https://www.rdocumentation.org/packages/tidyselect/versions/0.2.5/topics/select_helpers For example, maybe we want to see the first three columns reordered but the remaining columns to remain in the same order. Without everything(), we would need to specify each column in the select() call. With everything(), we can specify the first three columns to be lake, station_id, and sample_number followed by everything(). The columns will then be reordered accordingly (lake, station_id, sample_number, unique_id, etc.). reorder.df &lt;- taxa.df %&gt;% filter(unique_id == &quot;caz_1_1&quot;, order %in% c(&quot;ephemeroptera&quot;, &quot;trichoptera&quot;)) %&gt;% select(lake, station_id, sample_number, everything()) DT::datatable(reorder.df, options = list(scrollX = TRUE)) 16.0.5 distinct Definition: remove duplicate rows. Link: https://dplyr.tidyverse.org/reference/distinct.html After performing a subsetting columns with select(), it may be beneficial to subsequently run distinct() to remove any duplicate rows. Maybe we are just interested in viewing basic sample information such as lake, station_id, and sample_number. If select() is performed to subset the data frame to only represent these columns, then there will be many duplicate rows. The reason for this is in the original taxa.df data frame there are multiple taxa observed per sample. lake, station_id, and sample_number are associated accordingly with the taxa, and therefore lake, station_id, and sample_number are represented many times. nondistinct.df &lt;- taxa.df %&gt;% select(lake, station_id, sample_number) DT::datatable(nondistinct.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:3)))) distinct() will remove the duplicate rows present in the output above. This is a very simple call, which requires no input. distinct.df &lt;- taxa.df %&gt;% select(lake, station_id, sample_number) %&gt;% distinct() DT::datatable(distinct.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:3)))) 16.0.6 mutate Definition: create or overwrite columns. Link: https://dplyr.tidyverse.org/reference/mutate.html In the example below, I use the select() and distinct() combination from the distinct section and then filter the data frame to only include rows where lake equals “caz”. The distinct() call has insured that each row is unique but there is not a single column that could be used to uniquely identify a given sample. Using mutate() we can create a new column, called new_id, that concatenates the station_id and sample_number columns into a single value separated by an underscore (paste(station_id, sample_number, sep = \"_\")). mutate.df &lt;- taxa.df %&gt;% select(lake, station_id, sample_number) %&gt;% distinct() %&gt;% filter(lake == &quot;caz&quot;) %&gt;% mutate(new_id = paste(station_id, sample_number, sep = &quot;_&quot;)) DT::datatable(mutate.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:4)))) Maybe a second type of unique identifier is wanted for certain subsequent processes. mutate() allows for the creation of one or more columns within a single call. In the example below, new_id is created as it was in the example above but is followed by the creation of date_id. date_id is created by concatenating new_id and date columns. Therefore, a single mutate() call has created two new columns. Additionally, we can see that columns created downstream (date_id) can reference columns created upstream (new_id) within the mutate() call. mutate.df &lt;- taxa.df %&gt;% select(lake, station_id, sample_number, date) %&gt;% distinct() %&gt;% filter(lake == &quot;caz&quot;) %&gt;% mutate(new_id = paste(station_id, sample_number, sep = &quot;_&quot;), date_id = paste(new_id, date, sep = &quot;_&quot;)) DT::datatable(mutate.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:6)))) 16.0.7 group_by Definition: aggregate by specified columns. Link: https://dplyr.tidyverse.org/reference/group_by.html Calling group_by() will aggregate the data by the column(s) specified but alone will not alter the content of the data frame. group.df &lt;- taxa.df %&gt;% filter(unique_id %in% c(&quot;caz_1_1&quot;, &quot;caz_1_2&quot;)) %&gt;% select(unique_id, final_id, count) %&gt;% group_by(unique_id) knitr::kable(group.df) unique_id final_id count caz_1_1 physa 1 caz_1_1 gyraulus 1 caz_1_1 bezzia 5 caz_1_1 mallochohelea 7 caz_1_1 chironomus 1 caz_1_1 dicrotendipes 3 caz_1_1 paratanytarsus 34 caz_1_1 cricotopus 1 caz_1_1 psectrocladius 5 caz_1_1 thienemanniella 4 caz_1_1 krenopelopia 9 caz_1_1 procladius 1 caz_1_1 hemerodromia 1 caz_1_1 baetidae 1 caz_1_1 caenis 14 caz_1_1 acentria 1 caz_1_1 enallagma 1 caz_1_1 agraylea 1 caz_1_1 oxyethira 2 caz_1_1 hydroptilidae 1 caz_1_1 gammarus 2 caz_1_1 hyalella 14 caz_1_1 caecidotea 2 caz_1_2 amnicola_grana 2 caz_1_2 physa 27 caz_1_2 gyraulus_parvus 1 caz_1_2 helisoma_anceps 2 caz_1_2 promenetus_exacuous 5 caz_1_2 valvata 1 caz_1_2 bezzia 9 caz_1_2 mallochohelea 2 caz_1_2 chironomus 5 caz_1_2 dicrotendipes 4 caz_1_2 microtendipes 1 caz_1_2 polypedilum 2 caz_1_2 pseudochironomus 1 caz_1_2 rheotanytarsus 2 caz_1_2 thienemanniella 1 caz_1_2 ablabesmyia 5 caz_1_2 callibaetis 1 caz_1_2 caenis 1 caz_1_2 caenidae 2 caz_1_2 acentria 1 caz_1_2 mystacides 2 caz_1_2 gammarus 1 caz_1_2 hyalella 13 caz_1_2 caecidotea 9 The image below shows “under the hood”\" information about group.df from the Environment Tab before and after the group_by() call is made. We do not need to focus on the details associated with this “under the hood” information but this way we can view the change made by the group_by() call; unlike the table shown above, which does not provided any indication that the data has been aggregated. We can follow group_by() by a mutate() call to calculate a single value per group. Each group variable is replicated for each row within a group. In the example below, we are aggregating by two unique_ids (group_by(unique_id); “caz_1_1” and “caz_1_2”) and finding the total number of organisms identified within each group (mutate(total = sum(count))). The sum() function returns one number per group. mutate() then replicates this one number for all rows within a group. group.df &lt;- taxa.df %&gt;% filter(unique_id %in% c(&quot;caz_1_1&quot;, &quot;caz_1_2&quot;)) %&gt;% select(unique_id, final_id, count) %&gt;% group_by(unique_id) %&gt;% mutate(total = sum(count)) knitr::kable(group.df) unique_id final_id count total caz_1_1 physa 1 112 caz_1_1 gyraulus 1 112 caz_1_1 bezzia 5 112 caz_1_1 mallochohelea 7 112 caz_1_1 chironomus 1 112 caz_1_1 dicrotendipes 3 112 caz_1_1 paratanytarsus 34 112 caz_1_1 cricotopus 1 112 caz_1_1 psectrocladius 5 112 caz_1_1 thienemanniella 4 112 caz_1_1 krenopelopia 9 112 caz_1_1 procladius 1 112 caz_1_1 hemerodromia 1 112 caz_1_1 baetidae 1 112 caz_1_1 caenis 14 112 caz_1_1 acentria 1 112 caz_1_1 enallagma 1 112 caz_1_1 agraylea 1 112 caz_1_1 oxyethira 2 112 caz_1_1 hydroptilidae 1 112 caz_1_1 gammarus 2 112 caz_1_1 hyalella 14 112 caz_1_1 caecidotea 2 112 caz_1_2 amnicola_grana 2 100 caz_1_2 physa 27 100 caz_1_2 gyraulus_parvus 1 100 caz_1_2 helisoma_anceps 2 100 caz_1_2 promenetus_exacuous 5 100 caz_1_2 valvata 1 100 caz_1_2 bezzia 9 100 caz_1_2 mallochohelea 2 100 caz_1_2 chironomus 5 100 caz_1_2 dicrotendipes 4 100 caz_1_2 microtendipes 1 100 caz_1_2 polypedilum 2 100 caz_1_2 pseudochironomus 1 100 caz_1_2 rheotanytarsus 2 100 caz_1_2 thienemanniella 1 100 caz_1_2 ablabesmyia 5 100 caz_1_2 callibaetis 1 100 caz_1_2 caenis 1 100 caz_1_2 caenidae 2 100 caz_1_2 acentria 1 100 caz_1_2 mystacides 2 100 caz_1_2 gammarus 1 100 caz_1_2 hyalella 13 100 caz_1_2 caecidotea 9 100 This example can be taken one step further to calculate relative abundance (i.e., the percentage of the sample represented by each taxon) by adding percent = count / total * 100 to the mutate() call. group.df &lt;- taxa.df %&gt;% filter(unique_id %in% c(&quot;caz_1_1&quot;, &quot;caz_1_2&quot;)) %&gt;% select(unique_id, final_id, count) %&gt;% group_by(unique_id) %&gt;% mutate(total = sum(count), percent = count / total * 100) knitr::kable(group.df) unique_id final_id count total percent caz_1_1 physa 1 112 0.8928571 caz_1_1 gyraulus 1 112 0.8928571 caz_1_1 bezzia 5 112 4.4642857 caz_1_1 mallochohelea 7 112 6.2500000 caz_1_1 chironomus 1 112 0.8928571 caz_1_1 dicrotendipes 3 112 2.6785714 caz_1_1 paratanytarsus 34 112 30.3571429 caz_1_1 cricotopus 1 112 0.8928571 caz_1_1 psectrocladius 5 112 4.4642857 caz_1_1 thienemanniella 4 112 3.5714286 caz_1_1 krenopelopia 9 112 8.0357143 caz_1_1 procladius 1 112 0.8928571 caz_1_1 hemerodromia 1 112 0.8928571 caz_1_1 baetidae 1 112 0.8928571 caz_1_1 caenis 14 112 12.5000000 caz_1_1 acentria 1 112 0.8928571 caz_1_1 enallagma 1 112 0.8928571 caz_1_1 agraylea 1 112 0.8928571 caz_1_1 oxyethira 2 112 1.7857143 caz_1_1 hydroptilidae 1 112 0.8928571 caz_1_1 gammarus 2 112 1.7857143 caz_1_1 hyalella 14 112 12.5000000 caz_1_1 caecidotea 2 112 1.7857143 caz_1_2 amnicola_grana 2 100 2.0000000 caz_1_2 physa 27 100 27.0000000 caz_1_2 gyraulus_parvus 1 100 1.0000000 caz_1_2 helisoma_anceps 2 100 2.0000000 caz_1_2 promenetus_exacuous 5 100 5.0000000 caz_1_2 valvata 1 100 1.0000000 caz_1_2 bezzia 9 100 9.0000000 caz_1_2 mallochohelea 2 100 2.0000000 caz_1_2 chironomus 5 100 5.0000000 caz_1_2 dicrotendipes 4 100 4.0000000 caz_1_2 microtendipes 1 100 1.0000000 caz_1_2 polypedilum 2 100 2.0000000 caz_1_2 pseudochironomus 1 100 1.0000000 caz_1_2 rheotanytarsus 2 100 2.0000000 caz_1_2 thienemanniella 1 100 1.0000000 caz_1_2 ablabesmyia 5 100 5.0000000 caz_1_2 callibaetis 1 100 1.0000000 caz_1_2 caenis 1 100 1.0000000 caz_1_2 caenidae 2 100 2.0000000 caz_1_2 acentria 1 100 1.0000000 caz_1_2 mystacides 2 100 2.0000000 caz_1_2 gammarus 1 100 1.0000000 caz_1_2 hyalella 13 100 13.0000000 caz_1_2 caecidotea 9 100 9.0000000 16.0.7.1 ungroup Definition: remove the aggregation applied by group_by(). Link: https://dplyr.tidyverse.org/reference/group_by.html Once the calculations that required aggregation (i.e., group_by()) are complete, make sure to remove the aggregation from the data frame using ungroup(). If you forget to do this, R will continue to try to apply the aggregation to future calculations, which will most likely be inappropriate. Generally, you will eventually get an error message if you forget to use ungroup(). ungroup.df &lt;- taxa.df %&gt;% filter(unique_id %in% c(&quot;caz_1_1&quot;, &quot;caz_1_2&quot;)) %&gt;% select(unique_id, final_id, count) %&gt;% group_by(unique_id) %&gt;% mutate(total = sum(count), percent = count / total * 100) %&gt;% ungroup() knitr::kable(ungroup.df) unique_id final_id count total percent caz_1_1 physa 1 112 0.8928571 caz_1_1 gyraulus 1 112 0.8928571 caz_1_1 bezzia 5 112 4.4642857 caz_1_1 mallochohelea 7 112 6.2500000 caz_1_1 chironomus 1 112 0.8928571 caz_1_1 dicrotendipes 3 112 2.6785714 caz_1_1 paratanytarsus 34 112 30.3571429 caz_1_1 cricotopus 1 112 0.8928571 caz_1_1 psectrocladius 5 112 4.4642857 caz_1_1 thienemanniella 4 112 3.5714286 caz_1_1 krenopelopia 9 112 8.0357143 caz_1_1 procladius 1 112 0.8928571 caz_1_1 hemerodromia 1 112 0.8928571 caz_1_1 baetidae 1 112 0.8928571 caz_1_1 caenis 14 112 12.5000000 caz_1_1 acentria 1 112 0.8928571 caz_1_1 enallagma 1 112 0.8928571 caz_1_1 agraylea 1 112 0.8928571 caz_1_1 oxyethira 2 112 1.7857143 caz_1_1 hydroptilidae 1 112 0.8928571 caz_1_1 gammarus 2 112 1.7857143 caz_1_1 hyalella 14 112 12.5000000 caz_1_1 caecidotea 2 112 1.7857143 caz_1_2 amnicola_grana 2 100 2.0000000 caz_1_2 physa 27 100 27.0000000 caz_1_2 gyraulus_parvus 1 100 1.0000000 caz_1_2 helisoma_anceps 2 100 2.0000000 caz_1_2 promenetus_exacuous 5 100 5.0000000 caz_1_2 valvata 1 100 1.0000000 caz_1_2 bezzia 9 100 9.0000000 caz_1_2 mallochohelea 2 100 2.0000000 caz_1_2 chironomus 5 100 5.0000000 caz_1_2 dicrotendipes 4 100 4.0000000 caz_1_2 microtendipes 1 100 1.0000000 caz_1_2 polypedilum 2 100 2.0000000 caz_1_2 pseudochironomus 1 100 1.0000000 caz_1_2 rheotanytarsus 2 100 2.0000000 caz_1_2 thienemanniella 1 100 1.0000000 caz_1_2 ablabesmyia 5 100 5.0000000 caz_1_2 callibaetis 1 100 1.0000000 caz_1_2 caenis 1 100 1.0000000 caz_1_2 caenidae 2 100 2.0000000 caz_1_2 acentria 1 100 1.0000000 caz_1_2 mystacides 2 100 2.0000000 caz_1_2 gammarus 1 100 1.0000000 caz_1_2 hyalella 13 100 13.0000000 caz_1_2 caecidotea 9 100 9.0000000 The image below shows “under the hood”\" information about ungroup.df from the Environment Tab before and after the ungroup() call is made. We do not need to focus on the details associated with this “under the hood” information but this way we can view the change made by the ungroup() call; unlike the table shown above, which does not provided any indication that the data has been unaggregated. 16.0.8 summarize Definition: creates or overwrites columns but only retains columns specified in group_by() and the column(s) created in the summarize() call. This function requires group_by() to be called in advance. Link: https://dplyr.tidyverse.org/reference/summarise.html In the group_by example, we calculated the percentage of the sample comprised by each final_id taxon. final_id represents the highest taxonomic resolution for which these taxa were identified; therefore, each row represented a unique taxon. What if we want to explore these samples at a lower resolution? In the example below, the taxa are represented at the order-level. The percent calculations are correct but, in many cases, the same taxon is represented more than once. This is a poor representation of the data. summarize() can help us solve this issue in the subsequent code chunks. sub.df &lt;- taxa.df %&gt;% filter(unique_id %in% c(&quot;caz_1_1&quot;, &quot;caz_1_2&quot;)) %&gt;% select(unique_id, order, count) %&gt;% group_by(unique_id) %&gt;% mutate(total = sum(count), percent = count / total * 100) %&gt;% ungroup() knitr::kable(sub.df) unique_id order count total percent caz_1_1 basommatophora 1 112 0.8928571 caz_1_1 basommatophora 1 112 0.8928571 caz_1_1 diptera 5 112 4.4642857 caz_1_1 diptera 7 112 6.2500000 caz_1_1 diptera 1 112 0.8928571 caz_1_1 diptera 3 112 2.6785714 caz_1_1 diptera 34 112 30.3571429 caz_1_1 diptera 1 112 0.8928571 caz_1_1 diptera 5 112 4.4642857 caz_1_1 diptera 4 112 3.5714286 caz_1_1 diptera 9 112 8.0357143 caz_1_1 diptera 1 112 0.8928571 caz_1_1 diptera 1 112 0.8928571 caz_1_1 ephemeroptera 1 112 0.8928571 caz_1_1 ephemeroptera 14 112 12.5000000 caz_1_1 lepidoptera 1 112 0.8928571 caz_1_1 odonata 1 112 0.8928571 caz_1_1 trichoptera 1 112 0.8928571 caz_1_1 trichoptera 2 112 1.7857143 caz_1_1 trichoptera 1 112 0.8928571 caz_1_1 amphipoda 2 112 1.7857143 caz_1_1 amphipoda 14 112 12.5000000 caz_1_1 isopoda 2 112 1.7857143 caz_1_2 neotaenioglossa 2 100 2.0000000 caz_1_2 basommatophora 27 100 27.0000000 caz_1_2 basommatophora 1 100 1.0000000 caz_1_2 basommatophora 2 100 2.0000000 caz_1_2 basommatophora 5 100 5.0000000 caz_1_2 heterostropha 1 100 1.0000000 caz_1_2 diptera 9 100 9.0000000 caz_1_2 diptera 2 100 2.0000000 caz_1_2 diptera 5 100 5.0000000 caz_1_2 diptera 4 100 4.0000000 caz_1_2 diptera 1 100 1.0000000 caz_1_2 diptera 2 100 2.0000000 caz_1_2 diptera 1 100 1.0000000 caz_1_2 diptera 2 100 2.0000000 caz_1_2 diptera 1 100 1.0000000 caz_1_2 diptera 5 100 5.0000000 caz_1_2 ephemeroptera 1 100 1.0000000 caz_1_2 ephemeroptera 1 100 1.0000000 caz_1_2 ephemeroptera 2 100 2.0000000 caz_1_2 lepidoptera 1 100 1.0000000 caz_1_2 trichoptera 2 100 2.0000000 caz_1_2 amphipoda 1 100 1.0000000 caz_1_2 amphipoda 13 100 13.0000000 caz_1_2 isopoda 9 100 9.0000000 The most intuitive way to solve this problem, to sum the counts by unique and order columns before calculating the percentages, which can be down with a combination of group_by() and summarize(). Apply group_by() to the unique_id and order columns. group_by(unique_id, order) Use summarize() in the same way mutate() was applied in the mutate section. In this case, the count will be overwritten by the sum of the counts aggregated by the unique_id and order columns. summarize(count = sum(count)) Use ungroup() to remove the groupings created with group_by(). In the table output, we can see that each taxon, order, is only represented once per sample, unique_id. summarize.df &lt;- taxa.df %&gt;% filter(unique_id %in% c(&quot;caz_1_1&quot;, &quot;caz_1_2&quot;)) %&gt;% select(unique_id, order, count) %&gt;% group_by(unique_id, order) %&gt;% summarize(count = sum(count)) %&gt;% ungroup() knitr::kable(summarize.df) unique_id order count caz_1_1 amphipoda 16 caz_1_1 basommatophora 2 caz_1_1 diptera 71 caz_1_1 ephemeroptera 15 caz_1_1 isopoda 2 caz_1_1 lepidoptera 1 caz_1_1 odonata 1 caz_1_1 trichoptera 4 caz_1_2 amphipoda 14 caz_1_2 basommatophora 35 caz_1_2 diptera 32 caz_1_2 ephemeroptera 4 caz_1_2 heterostropha 1 caz_1_2 isopoda 9 caz_1_2 lepidoptera 1 caz_1_2 neotaenioglossa 2 caz_1_2 trichoptera 2 To calculate the percentage of each order, apply the group_by(), mutate(), and ungroup() combination from the group_by section. summarize.df &lt;- taxa.df %&gt;% filter(unique_id %in% c(&quot;caz_1_1&quot;, &quot;caz_1_2&quot;)) %&gt;% select(unique_id, order, count) %&gt;% group_by(unique_id, order) %&gt;% summarize(count = sum(count)) %&gt;% ungroup() %&gt;% group_by(unique_id) %&gt;% mutate(total = sum(count), percent = count / total * 100) %&gt;% ungroup() knitr::kable(summarize.df) unique_id order count total percent caz_1_1 amphipoda 16 112 14.2857143 caz_1_1 basommatophora 2 112 1.7857143 caz_1_1 diptera 71 112 63.3928571 caz_1_1 ephemeroptera 15 112 13.3928571 caz_1_1 isopoda 2 112 1.7857143 caz_1_1 lepidoptera 1 112 0.8928571 caz_1_1 odonata 1 112 0.8928571 caz_1_1 trichoptera 4 112 3.5714286 caz_1_2 amphipoda 14 100 14.0000000 caz_1_2 basommatophora 35 100 35.0000000 caz_1_2 diptera 32 100 32.0000000 caz_1_2 ephemeroptera 4 100 4.0000000 caz_1_2 heterostropha 1 100 1.0000000 caz_1_2 isopoda 9 100 9.0000000 caz_1_2 lepidoptera 1 100 1.0000000 caz_1_2 neotaenioglossa 2 100 2.0000000 caz_1_2 trichoptera 2 100 2.0000000 The previous code chunk works but it is getting very long. Long code chunks make it harder for your future self or others to interpret and can make it harder to find/troubleshoot bugs. Better practice would be to break the previous code chunk into 2-3 sub-tasks. The following code chunk into 3 sub-tasks, which should make it easier to follow process and allow us to observe the data after each sub-task is executed. Explanation of sub-tasks below: caz1.df: reduce the data frame down to only the rows and columns of interest. In this case, we are only interested in the two replicates from Cazenovia Lake site 1; therefore, I named the data frame caz1.df to describe the data represented within the data frame. order.df: summarize the taxonomic counts by the sample, unique_id, and taxonomic rank, order. percent.df: calculate the percentage of each sample, unique_id, represented by each taxon, order. caz1.df &lt;- taxa.df %&gt;% filter(unique_id %in% c(&quot;caz_1_1&quot;, &quot;caz_1_2&quot;)) %&gt;% select(unique_id, order, count) order.df &lt;- caz1.df %&gt;% group_by(unique_id, order) %&gt;% summarize(count = sum(count)) %&gt;% ungroup() percent.df &lt;- order.df %&gt;% group_by(unique_id) %&gt;% mutate(total = sum(count), percent = count / total * 100) %&gt;% ungroup() 16.0.9 Joins Link: https://dplyr.tidyverse.org/reference/join.html Definition: Combine two data sets by common features. “a” and “b” will be used in the descriptions below to represent two data sets. left_join Join only rows in “b” that have a match in “a” right_join Join only rows in “a” that have a match in “b” full_join Join all rows from “a” with all rows from “b” inner_join Join only rows that are present in both “a” and “b” semi_join Keep only rows in “a” that are found in “b” “b” is not actually joined with “a” This is more like a filter Opposite of an anti_join() anti_join Keep only rows in “a” that are NOT found in “b” “b” is not actually joined with “a” This is more like a filter Opposite of an semi_join() 16.0.9.1 left_join left.df &lt;- left_join(taxa.df, env.df, by = &quot;unique_id&quot;) DT::datatable(left.df, options = list(scrollX = TRUE)) 16.0.9.2 right_join right.df &lt;- right_join(taxa.df, env.df, by = &quot;unique_id&quot;) DT::datatable(right.df, options = list(scrollX = TRUE)) 16.0.9.3 full_join full.df &lt;- taxa.df %&gt;% filter(lake == &quot;onon&quot;) %&gt;% full_join(env.df, by = &quot;unique_id&quot;) DT::datatable(full.df, options = list(scrollX = TRUE)) 16.0.9.4 inner_join full.df &lt;- taxa.df %&gt;% filter(lake == &quot;onon&quot;) %&gt;% inner_join(env.df, by = &quot;unique_id&quot;) DT::datatable(full.df, options = list(scrollX = TRUE)) 16.0.9.5 semi_join semi.df &lt;- taxa.df %&gt;% filter(lake == &quot;onon&quot;) %&gt;% semi_join(env.df, by = &quot;unique_id&quot;) DT::datatable(semi.df, options = list(scrollX = TRUE)) 16.0.9.6 anti_join sub.df &lt;- taxa.df %&gt;% filter(lake == &quot;onon&quot;) anti.df &lt;- anti_join(env.df, sub.df, by = &quot;unique_id&quot;) DT::datatable(anti.df, options = list(scrollX = TRUE)) 16.0.9.7 nest_join nest.df &lt;- taxa.df %&gt;% filter(lake == &quot;onon&quot;) %&gt;% nest_join(env.df, by = &quot;unique_id&quot;) DT::datatable(nest.df, options = list(scrollX = TRUE)) 16.0.10 Bind Link: https://dplyr.tidyverse.org/reference/bind.html Definition: Append rows or columns on to a data frame. 16.0.10.1 bind_rows To show how bind_rows() work, let’s first split taxa.df into three data frames representing the three lakes in the data set. onon.df &lt;- taxa.df %&gt;% filter(lake == &quot;onon&quot;) otis.df &lt;- taxa.df %&gt;% filter(lake == &quot;ot&quot;) caz.df &lt;- taxa.df %&gt;% filter(lake == &quot;caz&quot;) If we wanted to combine these data frames back into one data frame, we can call all of them within bind_rows(). Generally, you want to have matching column headers; however, bind_rows() will recognize columns that are unique to one data frame and add them into the appended data frame. The data frame(s) that did not contain this column will have NA as the values in this column. bind.df &lt;- bind_rows(onon.df, otis.df, caz.df) DT::datatable(bind.df, options = list(scrollX = TRUE)) 16.0.10.2 bind_cols bind_cols() is similar to bind_rows() but instead appends columns. I rarely find use for this function becuase in general I would prefer a [Join]. Let’s extract the taxonomic hierarchy information from onon.df and store it as a data frame object called hier.df. hier.df &lt;- onon.df %&gt;% select(phylum:species) DT::datatable(hier.df, options = list(scrollX = TRUE)) Let’s extract the taxonomic count information from onon.df and store it as a data frame object called count.df. count.df &lt;- onon.df %&gt;% select(unique_id, final_id, count) DT::datatable(count.df, options = list(scrollX = TRUE)) hier.df and count.df have the same number of rows, and therefore the columns can be appended together with bind_cols() bind.df &lt;- bind_cols(count.df, hier.df) DT::datatable(bind.df, options = list(scrollX = TRUE)) "],
["tidyr.html", "17 tidyr", " 17 tidyr Link: https://tidyr.tidyverse.org/ Index of Functions: https://tidyr.tidyverse.org/reference/index.html Chapter of R for Data Science: https://r4ds.had.co.nz/tidy-data.html library(tidyr) suppressPackageStartupMessages( library(dplyr) ) 17.0.1 Example Data Import the example data. This data represents benthic macroinvertebrate data collected in the littoral zone of Onondaga, Otisco, and Cazenovia lakes. taxa.df &lt;- file.path(&quot;data&quot;, &quot;zms_thesis-macro_2017-06-18.csv&quot;) %&gt;% read.csv(stringsAsFactors = FALSE) Preprocess taxa.df to just represent order-level taxonomic counts per sample. For more details about this process see the summarize section. ord.df &lt;- taxa.df %&gt;% select(unique_id, order, count) %&gt;% group_by(unique_id, order) %&gt;% summarize(count = sum(count)) %&gt;% ungroup() DT::datatable(ord.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:3)))) 17.0.2 spread Definition: transpose data to a wide data format. Link: https://tidyr.tidyverse.org/reference/spread.html In some instances it might be beneficial to transpose a data frame from a long format to a wide format, which can be simply done with spread(). spread() requires two columns to be specified: key: a column name, for which the unique values in the column will become column headers. value: a column name, for which the values will be represented in the rows appropriately associated with the key column. The remaining columns will be used as an anchor point to represent a unique key for each row. If these remaining columns are not unique, an error will be returned. You will need to figure out why there are duplicate rows in the unique identifier columns and how to remedy the issue. In the example below, ord.df is transformed from a long to a wide format. order values now represent column headers and the values from the count column have been filled in appropriately under the associated new order column headers. wide.df &lt;- ord.df %&gt;% spread(order, count) DT::datatable(wide.df, options = list(scrollX = TRUE)) In the example above, any instance where a taxon was not found in a sample, the value is represented as an NA (represented as a blank space by the output of DT::datatable()). However, in this example it would be more appropriate to represent all of these values as a zero. To do this we just need to specify fill = 0 within the spread() call. In the table below, there are no NAs(represented as a blank space by the output of DT::datatable()). wide.df &lt;- ord.df %&gt;% spread(order, count, fill = 0) DT::datatable(wide.df, options = list(scrollX = TRUE)) 17.0.3 gather Definition: transpose data to a long data format. Link: https://tidyr.tidyverse.org/reference/gather.html In most instances, packages from the tidyverse are designed to operate on data in a long data format. gather() makes is it simple to convert a wide format to a long format. In the this code chunk, the wide.df is used from the spread section and will be converted from a wide to a long data format using gather(). order represents a new column name, which by default will include all column names from wide.df. count also represents a new column name, which will represent all of the values that were present in each column. If just gather(order, count) is applied, the unique_id is included within the order column and the values within from the unique_id column are included within the count column. This is not correct. The next code chunk will correct this issue. long.df &lt;- wide.df %&gt;% gather(order, count) DT::datatable(long.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:2)))) Adding -unique_id to the end of the gather() call will retain unique_id in the final output but exclude this column from being included in the conversion of the remaining headers to the order column and the remaining row values to the count column. One or more columns can be excluded following the -unique_id example. long.df &lt;- wide.df %&gt;% gather(order, count, -unique_id) DT::datatable(long.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:3)))) 17.0.4 complete Definition: “complete” a data frame by adding in missing combinations of data. Link: https://tidyr.tidyverse.org/reference/complete.html In the gather section, long.df has 1,440 rows, while taxa.df is only 1,402 rows. This descrepancy is due to taxa.df not containing any zero counts, while long.df has zero counts from transforming from a wide data format (wide.df). Having all possible combinations of taxa present per station can be helpful when plotting or performing calculations. If you are starting with a long data format, you do not want to convert it to a wide data format with spread() and then back to a long data format with gather(). Instead you can use complete() to fill in missing combinations. Here complete() is used to make sure each unique_id represents one row for each order-level (order) taxon in the data set. The fill arguement requires a list, within which you specify what value you want each column to represent if a new combination is added to the data set. In this example, new combinations means that a taxon was not identified in a given sample, and therefore the count should represent zero (count = 0). complete.df &lt;- ord.df %&gt;% complete(order, nesting(unique_id), fill = list(count = 0)) DT::datatable(complete.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:3)))) 17.0.5 separate Definition: divide a single column into multiple columns by some specified character or pattern. Link: https://tidyr.tidyverse.org/reference/separate.html In some instances, a data frame may contain a column that has concatenated information that is separated by a common character or pattern. It may be beneficial to extract this concatenated information into separate columns to make it easier to perform subsequent tasks, such as filtering. separate() can be used to make this a simple task. This example uses long.df from the gather section. In the separate() call: unique_id refers to the name of the column to be split c(\"lake\", \"station_id\", \"replicate\") refers to the new column names that the split values from unique_id will fill sep = \"_\" specifies that the strings in unique_id should be split by underscores The default of separate() is to remove (remove = TRUE) the original column unique_id from the returned data frame. sep.df &lt;- long.df %&gt;% separate(unique_id, c(&quot;lake&quot;, &quot;station_id&quot;, &quot;replicate&quot;), sep = &quot;_&quot;) DT::datatable(sep.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:5)))) I often find it helpful to specify remove = FALSE, which, in this example, will split unique_id into several new columns but also retain `unique_id in the final output. sep.df &lt;- long.df %&gt;% separate(unique_id, c(&quot;lake&quot;, &quot;station_id&quot;, &quot;replicate&quot;), sep = &quot;_&quot;, remove = FALSE) DT::datatable(sep.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:6)))) 17.0.6 unite Definition: concatenate multiple columns values into a single string represented in a new column. Link: https://tidyr.tidyverse.org/reference/unite.html unite() is the opposite of separate, it is used to combine values from multiple columns into a single string separated by a common character or pattern. Using sep.df, created in the separate section, columns lake, station_id, and replicate can be concatenated into a single string within a new column using unite(). In the unite() call: \"unique_id2\" refers to the new column name that will contain the concatenated strings from the subsequently specified columns c(\"lake\", \"station_id\", \"replicate\") refers to the column names that contain the values that we want to be concatenated in unique_id2. sep = \"_\" specifies that the strings from c(\"lake\", \"station_id\", \"replicate\") should be denoted in unique_id2 by an underscore The default of unite() is to remove (remove = TRUE) the concatenated columns (c(\"lake\", \"station_id\", \"replicate\")) from the returned data frame. unite.df &lt;- sep.df %&gt;% unite(&quot;unique_id2&quot;, c(&quot;lake&quot;, &quot;station_id&quot;, &quot;replicate&quot;), sep = &quot;-&quot;) DT::datatable(unite.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:4)))) In some cases I find it useful to specify remove = FALSE, which, in this example, will retain lake, station_id, and replicate in the final output. unite.df &lt;- sep.df %&gt;% unite(&quot;unique_id2&quot;, c(&quot;lake&quot;, &quot;station_id&quot;, &quot;replicate&quot;), sep = &quot;-&quot;, remove = FALSE) DT::datatable(unite.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:7)))) "],
["lubridate.html", "18 lubridate", " 18 lubridate Link: https://lubridate.tidyverse.org/ Index of Functions: https://lubridate.tidyverse.org/reference/index.html#section-date-time-parsing Cheat Sheet: https://rawgit.com/rstudio/cheatsheets/master/lubridate.pdf Chapter of R for Data Science: https://r4ds.had.co.nz/dates-and-times.html library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following object is masked from &#39;package:base&#39;: ## ## date suppressPackageStartupMessages( library(dplyr) ) 18.0.1 Example Data Import the example data. This data represents benthic macroinvertebrate data collected in the littoral zone of Onondaga, Otisco, and Cazenovia lakes. taxa.df &lt;- file.path(&quot;data&quot;, &quot;zms_thesis-macro_2017-06-18.csv&quot;) %&gt;% read.csv(stringsAsFactors = FALSE) Preprocess taxa.df to only include unique instances of station IDs and sample dates. For more details about this process see the select and distinct sections. dates.df &lt;- taxa.df %&gt;% select(station_id, date) %&gt;% distinct() DT::datatable(dates.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:2)))) 18.0.2 mdy, ymd, dmy, ymd_hms, … Definition: convert character or numeric data class to a date or datetime class. There are a lot of variations of this function that are specific to the format of your date or datetime. Link: https://www.rdocumentation.org/packages/lubridate/versions/1.7.4/topics/ymd In dates.df, the date column is imported as a character class and follows a “mm/dd/yyyy” format. The function mdy() can be used convert the character strings in the date column to a date class. mdy.df &lt;- dates.df %&gt;% mutate(date = mdy(date)) DT::datatable(mdy.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:2)))) In the example above, it is obvious the the format of the date has changed but it is not obvious that the R-class has changed. First look at the classes represented in the dates.df. sapply(dates.df, class) ## station_id date ## &quot;character&quot; &quot;character&quot; Then looking at the column classes in myd.df, we can see date has changed to class “Date”. sapply(mdy.df, class) ## station_id date ## &quot;character&quot; &quot;Date&quot; 18.0.3 year, month, mday, yday, hour, minute, and second Definition: these functions allow you to extract a specific feature of a date or datetime class. The returned values will no longer be a date or datetime class. Links: year: https://lubridate.tidyverse.org/reference/year.html month:https://lubridate.tidyverse.org/reference/month.html week: https://lubridate.tidyverse.org/reference/week.html day: https://lubridate.tidyverse.org/reference/day.html wday mday qday yday hour: https://lubridate.tidyverse.org/reference/hour.html minute: https://lubridate.tidyverse.org/reference/minute.html second: https://lubridate.tidyverse.org/reference/second.html Once a column is a date or datetime class, then lubridate functions make it easy to extract parts of the date, such as year, month, day, hour, minutes, seconds, etc. In the mutate() call below, I applied many but not all of the helpful functions for extracting datetime related information. The majority of these are straight forward; however, we can change label and abbr to alter the output of functions like month() and wday(). label label = FALSE returns a numeric value label = TRUE returns a character value abbr If label = FALSE, then abbr has no effect label = TRUE and abbr = TRUE returns an abbreviated character string week: Sun, Mon, Tue, Wed, Thu, Fri, Sat month: Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec label = TRUE and abbr = FALSE returns an full character string week: Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday month: January, February, March, April, May, June, July, August, September, October, November, December extract.df &lt;- mdy.df %&gt;% mutate(year = year(date), month_int = month(date), month_abv = month(date, label = TRUE), month_full = month(date, label = TRUE, abbr = FALSE), week = week(date), day = day(date), wday_int = wday(date), wday_abv = wday(date, label = TRUE), wday_full = wday(date, label = TRUE, abbr = FALSE), mday = mday(date), qday = qday(date), yday = yday(date), hour = hour(date), minute = minute(date), second = second(date)) DT::datatable(extract.df, options = list(scrollX = TRUE)) 18.0.4 round_date, floor_date, and ceiling_date Definition: round a date or datetime value by a specified unit of time. Links: https://lubridate.tidyverse.org/reference/round_date.html round_date() will round the date or datetime by the specified unit of time, such as “15 minutes”, “week”, “month”, or “year”. I find it really convient that you can specify to the nearest “15 minutes”. floor_date() and ceiling_date() provide similar functionality but always round down or up, respectively. round.df &lt;- mdy.df %&gt;% mutate(round_week = round_date(date, &quot;week&quot;), round_month = round_date(date, &quot;month&quot;), round_year = round_date(date, &quot;year&quot;), round_year5 = round_date(date, &quot;5 years&quot;), round_century = round_date(date, &quot;100 years&quot;), floor_month = floor_date(date, &quot;month&quot;), floor_year = floor_date(date, &quot;year&quot;), ceiling_month = ceiling_date(date, &quot;month&quot;), ceiling_year = ceiling_date(date, &quot;year&quot;)) DT::datatable(round.df, options = list(scrollX = TRUE, autoWidth = TRUE, columnDefs = list(list(width = &#39;70px&#39;, targets = c(2))))) "],
["ggplot2.html", "19 ggplot2", " 19 ggplot2 Link: https://ggplot2.tidyverse.org/ Index of Functions: https://ggplot2.tidyverse.org/reference/index.html Cheat Sheet: https://github.com/rstudio/cheatsheets/blob/master/data-visualization-2.1.pdf Chapter of R for Data Science: https://r4ds.had.co.nz/data-visualisation.html https://r4ds.had.co.nz/graphics-for-communication.html R Graphics Cookbook: http://www.cookbook-r.com/Graphs/ library(ggplot2) suppressPackageStartupMessages( library(dplyr) ) library(tidyr) 19.0.1 Example Data Import the example data. This data represents benthic macroinvertebrate data collected in the littoral zone of Onondaga, Otisco, and Cazenovia lakes. taxa.df &lt;- file.path(&quot;data&quot;, &quot;zms_thesis-macro_2017-06-18.csv&quot;) %&gt;% read.csv(stringsAsFactors = FALSE) Preprocess taxa.df to just represent order-level taxonomic counts per sample. For more details about this process see the summarize section. ord.df &lt;- taxa.df %&gt;% select(unique_id, station_id, lake, order, count) %&gt;% group_by(unique_id, station_id, lake, order) %&gt;% summarize(count = sum(count)) %&gt;% ungroup() %&gt;% group_by(station_id, lake, order) %&gt;% summarize(count = mean(count)) %&gt;% ungroup() DT::datatable(ord.df, options = list(columnDefs = list(list(className = &#39;dt-center&#39;, targets = 0:3)))) Calculate the calculate relative abundance (i.e., the percentage of the sample represented by each taxon) of each taxon within a sample. For more details about this process see the group_by section. pct.df &lt;- ord.df %&gt;% group_by(station_id) %&gt;% mutate(total = sum(count), percent = count / total * 100) %&gt;% ungroup() %&gt;% tidyr::complete(order, nesting(station_id, lake, total), fill = list(count = 0, percent = 0)) %&gt;% mutate(lake = factor(lake, levels = c(&quot;onon&quot;, &quot;ot&quot;, &quot;caz&quot;))) 19.0.2 ggplot Definition: “initializes a ggplot object.” (quote from link below) Link: https://ggplot2.tidyverse.org/reference/ggplot.html Generally, you want to start with a ggplot() call. Here we can see a blank figure template returned when ggplot() is called and pct.df is specified as data. The pipe operator can be used to pipe data into ggplot() but it cannot be used to chain subsequent ggplot2 functions together. ggplot(pct.df) pct.df %&gt;% ggplot() 19.0.3 aes Definition: specify aesthetics (x-axis, y-axis, color, fill, shape, size, linetype, etc.) Link: https://ggplot2.tidyverse.org/reference/aes.html To start to format the figure, you will want to use aes(). When using aes() within ggplot(), you are specifying global variables. For instance, you will generally specify the columns, from the specified data frame (e.g., pct.df), that will represent your x-axis and y-axis. In the example below, the lake column represents the x-axis, while the percent column will represents the y-axis. Now we have a template for our figure but we will want to add layers (boxplot, scatter plot, bar plot) to this feature to visualize our data. pct.df %&gt;% ggplot(aes(x = lake, y = percent)) ### Adding Layers (+) ggplot2 does not recognize the pipe operator (%&gt;%), instead it uses + to add components to a plot. Now let’s add data to the plot by adding a + at the end of ggplot() and then specifying the plot type we are interested in creating. All plot functions in ggplot2 start with the prefix “geom_”. 19.0.4 geom_boxplot Definition: create box and whisker plots Link: https://ggplot2.tidyverse.org/reference/geom_boxplot.html Here we will create a box and whisker plot using geom_boxplot(). For this example, we will only focus on the percentage of Ephemeroptera (Mayflies) found within each lake by using the filter() function before the ggplot() function. The aesthetics have been specified within ggplot(), therefore geom_boxplot() can be called without any arguments. pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent)) + geom_boxplot() 19.0.4.1 Fill The color of the interquartile boxes can be specified with fill. In this example, fill = lake, which ggplot2 will automatically realize represents three categories and use a default color palette that is used to automatically color the plot. fill is specified within aes() within the ggplot() , and therefore this specification carries through to the subsequent geom_boxplot() call. pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent, fill = lake)) + geom_boxplot() 19.0.4.2 Color Color can be sepecified in a similar manner to Fill. In the plot below, we can see the difference between color and fill (the previous plot). pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent, color = lake)) + geom_boxplot() When I first started using ggplot2, I would frequently try to put the color or other aesthetic arguments outside of the aes() call. For example, in ggplot(aes(x = lake, y = percent), color = lake), color = lake is not within the aes() call. Therefore, it has no effect on the plot (i.e., there is no color added to the plot). pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent), color = lake) + geom_boxplot() aes() and the color or other aesthetics can also be specified within the geom_boxplot() call. This allows you to be more specific of which feature you want to recieve a given aesthetic. pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent)) + geom_boxplot(aes(color = lake)) Additionally, if you want to specify specific colors not based on features from your data frame (e.g., lake), then you can specify these colors within the geom_boxplot() call. Note, that color is NOT specified within an aes() call. pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent)) + geom_boxplot(color = c(&quot;purple&quot;, &quot;orange&quot;, &quot;brown&quot;)) If you do attempt to wrap manually specified colors, like color = c(\"purple\", \"orange\", \"brown\"), within aes(), you will get an error. pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent)) + geom_boxplot(aes(color = c(&quot;purple&quot;, &quot;orange&quot;, &quot;brown&quot;))) ## Error: Aesthetics must be either length 1 or the same as the data (48): colour Also, trying to manually specify colors within the ggplot() call will have no effect on the plot. pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent), color = c(&quot;purple&quot;, &quot;orange&quot;, &quot;brown&quot;)) + geom_boxplot() 19.0.4.3 geom_point Definition: add points to a plot Link: https://ggplot2.tidyverse.org/reference/geom_point.html Let’s add another layer to the plot above. geom_point() can be used to vizualize where the data points actually fall relative to the box and whisker plots. pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent)) + geom_boxplot() + geom_point() 19.0.4.4 geom_jitter Definition: add points to a plot that have been randomly offplaced from their actual position to avoid point overlap Link: https://ggplot2.tidyverse.org/reference/geom_jitter.html In the geom_point plot above, it is not possible to know if a point represents a single sample or if there are more than one samples with the same value overlaid on one another. geom_jitter() can be used to randomly offset the points from thier actual position to avoid the overlap issue present in geom_point(). In this example, geom_jitter() is used to offest the points overlaid on the box and whisker plots. The points are colored by lake within this call: geom_jitter(aes(color = lake)). Additionally, the outliers plotted from geom_boxplot() are hidden with geom_boxplot(outlier.shape = NA). These outliers are represented in the geom_jitter() call; therefore, if the outliers were not removed from geom_boxplot(), these points would be represented twice. pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent)) + geom_boxplot(outlier.shape = NA) + geom_jitter(aes(color = lake)) Here we can see what happens if color is specified within the ggplot() call. Now the box and whisker lines and the points are colored by lake. This is in contrast to the last plot, where only the points were colored by lake. pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent, color = lake)) + geom_boxplot(outlier.shape = NA) + geom_jitter() 19.0.4.5 geom_violin Definition: create violin plots a way of visualizing point density and distribution Link: https://ggplot2.tidyverse.org/reference/geom_violin.html This plot helps us to see that there are a lot of samples from Onondaga Lake (“onon”) that have no Ephemeroptera (percent = 0). pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent, fill = lake)) + geom_violin() 19.0.4.6 geom_dotplot Definition: create dot plots or beeswarm plots a way of visualizing point density and distribution Link: https://ggplot2.tidyverse.org/reference/geom_dotplot.html Similar to [violin_plots], geom_dotplot() can be more informative than a box and whisker plot. pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent, fill = lake)) + geom_dotplot(binaxis = &quot;y&quot;, stackdir = &quot;center&quot;, binwidth = 0.25) geom_dotplot() could be overlaid on geom_boxplot(), which may be a better than a geom_jitter example. pct.df %&gt;% filter(order == &quot;ephemeroptera&quot;) %&gt;% ggplot(aes(x = lake, y = percent)) + geom_boxplot(outlier.shape = NA) + geom_dotplot(aes(fill = lake), binaxis = &quot;y&quot;, stackdir = &quot;center&quot;, binwidth = 0.25) 19.0.4.7 geom_bar Definition: create bar plots Link: https://ggplot2.tidyverse.org/reference/geom_bar.html For this section, the data will need to be summarized by lake. The data is aggregated by lake and order, and the median abundance (count) is calculated. The top five taxa observed are retained as normal but the remaining taxa are lumped and reclassified as “Other” (forcats::fct_lump(factor(order), n = 5, w = percent)). The taxa are then sorted in descending order based on the taxa most commonly observed (forcats::fct_reorder(order, percent, median, .desc = TRUE)). abund.df &lt;- pct.df %&gt;% group_by(lake, order) %&gt;% summarise(count = median(count)) %&gt;% ungroup() %&gt;% mutate(order = forcats::fct_lump(factor(order), n = 5, w = count), order = forcats::fct_reorder(order, count, median, .desc = TRUE), lake = factor(lake, c(&quot;onon&quot;, &quot;ot&quot;, &quot;caz&quot;))) DT::datatable(abund.df, options = list(scrollX = TRUE)) Using geom_bar(), we can generate a bar plot. state = \"identity\" must be used when a y value is specified in aes(); otherwise, ggplot2 will simiply count the number of x value instances to create a y-axis count. WARNING: This plot is a quick example of geom_bar() and is not a good representation of the data. In this case, the median abundance was calculated for each taxon within each lake. geom_bar() is summing the median values per taxon per lake to produce this figure. abund.df %&gt;% ggplot(aes(x = order, y = count)) + geom_bar(stat = &quot;identity&quot;) As the warning above notes, the above plot is not a great representation of the data because it essentially sums the three median abundance values per taxon per lake to produce the bars. We can see this breakdown by adding fill = TRUE. This is also a poor way of view this data. abund.df %&gt;% ggplot(aes(x = order, y = count, fill = lake)) + geom_bar(stat = &quot;identity&quot;) position = \"dodge\" can be added to the geom_bar() call to make the bars for each lake appear side-by-side. abund.df %&gt;% ggplot(aes(x = order, y = count, fill = lake)) + geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) 19.0.4.7.1 Stacked Bar Plots Another great way to visualize this data is to create stacked bar plots. Stacked bar plots are almost always the better alternative to pie charts. In general, stack bar charts provide a more straight forward representation of quantity, which makes it easier to compare multiple stacked bar charts, then multiple pie charts. Note that in this section the x-axis now represents lake, the y-axis represents count, and the fill represents order. Stacked bar plots can be created by adding position = \"stack\" to the geom_bar() call. This information is exactly the same as the geom_bar() plot above, where position = \"dodge\" but it is more condensed. abund.df %&gt;% mutate(order = forcats::fct_reorder(order, count, median)) %&gt;% ggplot(aes(x = lake, y = count, fill = order)) + geom_bar(stat = &quot;identity&quot;, position = &quot;stack&quot;) Stacked bar plots can also be created by adding position = \"fill\" to the geom_bar() call. This effectively calculates relative abundance, the percentage each taxon represents within a lake. This normalizes the data and makes it easier to compare between lakes. abund.df %&gt;% mutate(order = forcats::fct_reorder(order, count, median)) %&gt;% ggplot(aes(x = lake, y = count, fill = order)) + geom_bar(stat = &quot;identity&quot;, position = &quot;fill&quot;) 19.0.4.8 geom_point (Scatter Plot) Definition: add points to a plot Link: https://ggplot2.tidyverse.org/reference/geom_point.html Creating a scatter plot is probably a more common use for geom_point() then the use from the geom_point section above. The pct.df data frame is converted from a long to a wide data format using spread. This data will be used throughout this section. wide.df &lt;- pct.df %&gt;% select(station_id, lake, percent, order) %&gt;% spread(order, percent) Diptera and Amphipoda were the two must frequently identified taxonomic orders in this data set. Let’s see if there is a relationship between these organisms by plotting counts of Diptera on the x-axis and counts of Amphipoda on the y-axis. geom_point() is used to create a scattter plot. There appears to be an inverse relationship between the number of amphipods observed and the number of diptera observed. wide.df %&gt;% ggplot(aes(x = diptera, y = amphipoda)) + geom_point() We can color the points by lake to see if this pattern is consistent accross lakes. wide.df %&gt;% ggplot(aes(x = diptera, y = amphipoda)) + geom_point(aes(color = lake)) 19.0.4.9 geom_line Definition: draw a line between points Link: https://ggplot2.tidyverse.org/reference/geom_path.html A common mistake I make is to use geom_line() instead of geom_smooth(). geom_line() will connect points direcetly but I ussually want a linear model. wide.df %&gt;% ggplot(aes(x = diptera, y = amphipoda)) + geom_point(aes(color = lake)) + geom_line() 19.0.4.10 geom_smooth Definition: plot a linear model (e.g., linear model, LOESS) Link: https://ggplot2.tidyverse.org/reference/geom_smooth.html geom_smooth() allows you to specify a method, such as “lm” (linear model) or “loess” (LOESS) and a formula (such as y ~ x). In the figure below, a linear model is created using all of the data. The blue line represents the linear model and the gray band represents the standard error around the model. wide.df %&gt;% ggplot(aes(x = diptera, y = amphipoda)) + geom_point(aes(color = lake)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x) Maybe we want to create a linear model per lake. This can be done by specifying color = lake within the ggplot() aes() call. Now we can see that all lakes have a similar slope but Otisco Lake has less variability in Amphipoda and Diptera counts. wide.df %&gt;% ggplot(aes(x = diptera, y = amphipoda, color = lake)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x) The standard error bands in the figure above make it difficult to read the plot. These bands can be removed by specifying se = FALSE in the geom_smooth() call. wide.df %&gt;% ggplot(aes(x = diptera, y = amphipoda, color = lake)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE) We may also be interested in creating a LOESS curve for all of the data. This can be done by specifying method = \"loess\" within geom_smooth(). wide.df %&gt;% ggplot(aes(x = diptera, y = amphipoda)) + geom_point(aes(color = lake)) + geom_smooth(method = &quot;loess&quot;, formula = y ~ x) Again, color and fill can be specified in the ggplot() aes() call to apply these features globably. The plot below shows a LOESS curve for each lake. color influenced the point and line color in the plot, while fill influenced the color of the standard error bands. wide.df %&gt;% ggplot(aes(x = diptera, y = amphipoda, color = lake, fill = lake)) + geom_point(aes(color = lake)) + geom_smooth(method = &quot;loess&quot;, formula = y ~ x) 19.0.4.11 facet_wrap Definition: replicate a plot by a specified feature or features Link: https://ggplot2.tidyverse.org/reference/facet_wrap.html facet_wrap() is one of my favorite functions. It allows you to create multiple plots at once base on a specified feature or features. For this example the data are modified in a manner that will allow us to compare the counts of each order to Diptera counts. The ~order within facet_wrap() specifies that we want to aggregate and loop through each unique string in the order column. pct.df %&gt;% select(station_id, lake, percent, order) %&gt;% spread(order, percent) %&gt;% gather(order, count, amphipoda:veneroida, -diptera) %&gt;% ggplot(aes(x = diptera, y = count, color = lake, fill = lake)) + geom_point(aes(color = lake)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE) + facet_wrap(~order) The defaults for the facet_wrap() arguements above make it a little hard to read all of the plots becuase they do not have the range of the Diptera vs. Amphipoda. the scales arguement can be used to “free” all of the axis (scales = \"free\"). This scales each of the x- and y-axes ranges specific to each plot, rather than standardizing across all plots. scales “free_x” = y-axis standardized across plots but x-axis is specific to each plot “free_y” = x-axis standardized across plots but y-asix is specific to each plot “free” = both x- and y-axes are specific to each plot pct.df %&gt;% select(station_id, lake, percent, order) %&gt;% spread(order, percent) %&gt;% gather(order, count, amphipoda:veneroida, -diptera) %&gt;% ggplot(aes(x = diptera, y = count, color = lake, fill = lake)) + geom_point(aes(color = lake)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE) + facet_wrap(~order, scales = &quot;free&quot;) Additionally, ncol (number of columns) can be used to modify the organization of figures. pct.df %&gt;% select(station_id, lake, percent, order) %&gt;% spread(order, percent) %&gt;% gather(order, count, amphipoda:veneroida, -diptera) %&gt;% ggplot(aes(x = diptera, y = count, color = lake, fill = lake)) + geom_point(aes(color = lake)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE) + facet_wrap(~order, scales = &quot;free&quot;, ncol = 1) We can use more than one feature to facet_wrap() by. For example, in the call below the plots are aggregated by order and lake (~order + lake). pct.df %&gt;% select(station_id, lake, percent, order) %&gt;% spread(order, percent) %&gt;% gather(order, count, amphipoda:veneroida, -diptera) %&gt;% ggplot(aes(x = diptera, y = count, color = lake, fill = lake)) + geom_point(aes(color = lake)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE) + facet_wrap(~order + lake, ncol = 3) "],
["shiny.html", "20 Shiny 20.1 What is Shiny? 20.2 Resources 20.3 Project Composition 20.4 Helpful R-Packages 20.5 Publishing 20.6 Data Management", " 20 Shiny Link: https://shiny.rstudio.com/ “Get Started” has great video tutorials “Gallery” examples of shiny apps 20.1 What is Shiny? Shiny is an R package that enables the developer to create interactive web applications (apps). My Example: https://zsmith.shinyapps.io/WQT_Shiny/ 20.2 Resources R Studio has a website dedicated shiny (https://shiny.rstudio.com/). There are a lot of resources available here but for those just learning shiny or looking for a shiny refresher I would direct you to the tutorial page (https://shiny.rstudio.com/tutorial/). 20.3 Project Composition Shiny apps are mainly composed of three files: 1) ui.R, 2) server.R, and 3) global.R. 20.3.1 ui.R In this file, you will specify the aesthetic aspects of the app. This includes: the presence/absence of a navigation bar, the presence and position of a dropdown menu, the presence and position of a sliderbar, and the location of figure created in the server.R file. 20.3.2 server.R In this file, you will specify reactive functions that respond to user inputs. For example, an app may contain a dropdown menu of sample sites and scatterplot representing the site selected in the dropdown menu. Each time the user selects a new sample site from the dropdown menu the scatterplot would update. 20.3.3 global.R In this file, you should include code that is static. This includes: loading libraries, sourcing functions, and potentially importing data. These activities are intended to occur once and will not be reacting to user inputs. 20.3.4 Structure Shiny projects generally grow rapidly and it can become difficult to navigate hundreds of lines of code in a ui.R or server.R file. My preference is to break the code up into independent and more manageable scripts that are sourced in the ui.R or server.R files. For example, imagine you are developing an app which contains two tabs, one dedicated to tabular data and one dedicated to an interactive map. I would develop separate R scripts for server code associated with each tab. Similarly, I would create separate R scripts for the ui code associated with each tab. These files are stored in the appropriate folders labeled either “ui” or “server.” When sourcing files in a shiny app you must specify “local = TRUE”. source(&quot;server/select_import_server.R&quot;, local = TRUE) 20.3.5 R-Packages Most Shiny apps will require multiple R-packages. I recommend loading all of the necessary R-packages in the global.R file. This makes it simple to identify all the packages you must have installed locally to edit and develop a given shiny app. One way to simplify this task is to use the example provided by the following link: https://www.r-bloggers.com/install-and-load-missing-specifiedneeded-packages-on-the-fly/. Following this scripts template: You specify all of the necessary R-packages. The code checks that all these packages are installed. If any packages are not installed, the code will install these packages. This makes it easier to collaborate with others or work on multiple computers. 20.4 Helpful R-Packages 20.4.1 DT (Interactive Tables) *Link: https://rstudio.github.io/DT/ The R-package, DT, is great resource for creating interactive tables. 20.4.2 dygraphs (Interactive Time Series Plots) *Link: https://rstudio.github.io/dygraphs/ The R-package, dygraphs, is great resource for creating interactive time series plots. 20.4.3 leaflet (Interactive Maps) *Link: http://rstudio.github.io/leaflet/ The R-package, Leaflet, is a great resource for creating interactive maps. When using this package in shiny there are a few steps you need to take to make the map function well (http://rstudio.github.io/leaflet/shiny.html). It is generally useful to create a leafletProxy, which will load the base map as shiny output. You can then use reactive functions to update the points presented on the map. Using leafletProxy, only the map points will update, the base map will remain unchanged. This prevents the need to reload the entire map each time the points are updated, which makes it appear that the map is flashing. 20.4.4 plotly (Interactive Figures) *Link: https://plot.ly/r/ The R-package, plotly, is great resource for creating interactive figures. 20.5 Publishing *Link: http://www.shinyapps.io/ shinyapps.io is a shiny hosting platform provided by R Studio. Users must create a shinyapps.io free account or a paid account. The free account limits the number of applications you can publish and the number of hours the app can be active per month. There are multiple tiers to the paid accounts. As the user pays more, the user can publish a greater amount of applications, more active hours are available per month, and other additional benefits are supplied by R Studio. 20.5.1 How to Publish to shinyapps.io Click on the “Publish to Server” button located in the top right corner of the source pane. A drop-down menu will appear. Select the appropriate shinyapps.io app. If this is your first time connecting to a shinyapps.io account. Make sure you have created a shinyapps.io account (https://www.shinyapps.io/admin/#/login). In the drop-down menu select “Manage Accounts.” This will bring you to the “Publishing Accounts” section of R Studios “Options.” Select “Connect…” -&gt; “ShinyApps.io” option -&gt; follow instructions. The “Publish to Server” window will appear. Select all of the files that are necessary for the app to run. Do not include unnecessary files, as this could slow down your app or make the app too large to host under your current account settings. Check the “Launch browser” check box. Click “Publish.” A “Deploy” tab will appear in the console pane, which will inform you that R Studio is working on publishing your app. This will take a few minutes. If there are any issues, the app will stop deploying and you will receive an error message. 20.6 Data Management 20.6.1 Small Data Sets If the data set(s) are small, then the data should be stored within the R project folder and can be published to shinyapps.io along with the rest of the files necessary to run the app. 20.6.2 Large Data Sets If the data set(s) are large or expected to grow, then the data should be stored in a cloud database. Large data files will be rejected from shinyapps.io. Use the following link as a more comprehensive description of how to work with databases in shiny (https://shiny.rstudio.com/articles/overview.html). Shinyapps.io is intended to host the code associated with the app, not the data associated with the app. A cloud-based database can be used to store data and the shiny app can reference this data. The database cannot be hosted from your local computer because once the app is published on shinyapps.io it will not be able to access your local files or databases. If the database structure does not change, any additional data appended to the database will be automatically accessible through the shiny app without the need to modify any of the shiny app code. 20.6.2.1 Creating and Managing a Cloud Database This section is technically independent of shiny but you will need to follow these steps to set up a cloud database. 20.6.2.2 Connecting to a Cloud Based Database To establish a connection with a database, use the pool package (https://shiny.rstudio.com/articles/pool-basics.html). The pool package aids in the management of database queries, which can be complicated. Below is an example of how to use the pool package function dbPool. You will need to indicate: driver class (drv; e.g., PostgreSQL), database name (dbname), database host (host), your database username (user), and your database password (password). pool &lt;- pool::dbPool(drv = RPostgreSQL::PostgreSQL(), dbname = &quot;database_name&quot;, host = &quot;cpanel.example.org&quot;, user = &quot;smitty&quot;, password = &quot;example&quot;) At the beginning of your server.R file you establish the connection to the link created by the pool package using the function poolCheckout. conn &lt;- pool::poolCheckout(pool) At the end of your server.R file you return the connection to the link created by the pool package using the function poolReturn. pool::poolReturn(conn) These two functions should encapsulate all queries made to the database and help perform the necessary steps to prevent issues from occurring. Within the sever.R file, you can then use the DBI package to query the database. For example, if you want to import a table from a database you can use the DBI function dbReadTable. new.object &lt;- dbReadTable(conn, &quot;table_name&quot;) "],
["default-shiny-example.html", "21 Default Shiny Example", " 21 Default Shiny Example If you select the “Single File” option when creating a shiny application, you will get the example code below. This file contains both the ui and server aspects of our shiny app. This works well if the app is very simple, but I find this becomes very difficult to manage as the app becomes more complex. The app is rendered below the code chunk; you should be able to interact with it. Let’s walk through the logic of this app. ui The ui represents a fluidPage() titlePanel() hads a title to the app Create an application with a sidebar using sidebarLayout() Specify what should be represented in the sidebar within sidebarPanel() This app includes a slider using sliderInput() Specify what should appear outside of the sidebar using mainPanel() Plot the output from the object created within the server using plotOutput(). “distPlot” within plotOutput() is in reference to the object output$distPlot created in the server with renderPlot() server server represents a function with two arguements input and output input represents objects from the ui output represents objects that were created in the server but you want to reference in the ui renderPlot() is used, in this case, to create an histogram for which bin size can be updated This object is stored using output$distPlot &lt;- renderPlot({}). Specifying output allows us to reference this object in the ui. distPlot is the name we will use in the ui to reference this object, which can be seen in the ui call plotOutput(\"distPlot\") renderPlot({}) requires curly brackets “{}” within the function call Within renderPlot({}) is the code that creates the histogram x &lt;- faithful[, 2] subsets the faithful data set (pre-loaded in base-R) x represents the second column of faithful stored as a vector. bins &lt;- seq(min(x), max(x), length.out = input$bins + 1) bins will be used to specify the break-points used to create the bin size in the histogram creation seq(from, to, length.out) sequence from one value to another length.out is used to specify how many breakpoints should be between the specified from and to arguements length.out = input$bins + 1 input$bins comes from the sliderInput() within the ui input$bins is that part that provides the updates to the histogram, ultimately making this app interactive hist(x, breaks = bins, col = 'darkgray', border = 'white') hist() creates a histogram plot x is the faithful vector created above breaks = bins specify the break-points for the histogram bars col = 'darkgray' specify the color of the histogram bars border = 'white' specify the color of the outline around the histogram bars shinyApp(ui = ui, server = server) The arguements to shinyApp() are ui and server Renders the shiny app by specifying the appropriate ui and server objects In this case, the arguements to shinyApp() are the same as the object names # # This is a Shiny web application. You can run the application by clicking # the &#39;Run App&#39; button above. # # Find out more about building applications with Shiny here: # # http://shiny.rstudio.com/ # library(shiny) ## Warning: package &#39;shiny&#39; was built under R version 3.5.3 # Define UI for application that draws a histogram ui &lt;- fluidPage( # Application title titlePanel(&quot;Old Faithful Geyser Data&quot;), # Sidebar with a slider input for number of bins sidebarLayout( sidebarPanel( sliderInput(&quot;bins&quot;, &quot;Number of bins:&quot;, min = 1, max = 50, value = 30) ), # Show a plot of the generated distribution mainPanel( plotOutput(&quot;distPlot&quot;) ) ) ) # Define server logic required to draw a histogram server &lt;- function(input, output) { output$distPlot &lt;- renderPlot({ # generate bins based on input$bins from ui.R x &lt;- faithful[, 2] bins &lt;- seq(min(x), max(x), length.out = input$bins + 1) # draw the histogram with the specified number of bins hist(x, breaks = bins, col = &#39;darkgray&#39;, border = &#39;white&#39;) }) } # Run the application shinyApp(ui = ui, server = server) ## PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable. Shiny applications not supported in static R Markdown documents "]
]
